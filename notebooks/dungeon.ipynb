{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyN5n7cfkzWj0t1YMHeZ1rPP"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Setup"
      ],
      "metadata": {
        "id": "jqMXo3jlS_Qa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FvTtqJT10d8D"
      },
      "outputs": [],
      "source": [
        "!pip install torch torchvision\n",
        "!pip install git+https://github.com/modAL-python/modAL.git\n",
        "!pip install skorch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#@title import libraries\n",
        "import random\n",
        "from google.colab import drive\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "from keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split\n",
        "import json\n",
        "import os\n",
        "import pdb\n",
        "from modAL.models import ActiveLearner\n",
        "from modAL.uncertainty import uncertainty_sampling\n",
        "from modAL.uncertainty import margin_sampling\n",
        "from modAL.uncertainty import entropy_sampling\n",
        "from skorch import NeuralNetClassifier\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from torchvision.transforms import ToTensor\n",
        "from sklearn.metrics import accuracy_score\n",
        "from skorch.callbacks import Callback\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "IRljWt_W0iUB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# utilities"
      ],
      "metadata": {
        "id": "kyKdjvhlTJhA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the categories using a dictionary\n",
        "category_dict = {\"X\": \"block\",\n",
        "                 \"/\": \"structure1\",\n",
        "                 \"\\\\\": \"structure2\",\n",
        "                 \"#\": \"Enemy\",\n",
        "                 \"*\": \"switch\",\n",
        "                 \"^\": \"spike\",\n",
        "                 \"&\": \"food\",\n",
        "                 \"-\": \"food\"}\n",
        "\n",
        "def merge_dict_keys(dict_in):\n",
        "    # create a new dictionary with merged keys\n",
        "    dict_out = {}\n",
        "    for key, value in dict_in.items():\n",
        "        if value not in dict_out:\n",
        "            dict_out[key] = value\n",
        "        else:\n",
        "            dict_out[key] += ', ' + value\n",
        "\n",
        "    # remove redundant key-value pairs\n",
        "    dict_out = {v: k for k, v in dict_out.items()}\n",
        "    return {v: k for k, v in dict_out.items()}\n",
        "\n",
        "merged_category_dict = merge_dict_keys(category_dict)\n",
        "print(merged_category_dict)\n",
        "def create_matrix(string):\n",
        "    # Split the string into rows using newline characters.\n",
        "    rows = string.split('\\n')\n",
        "    # Remove any empty rows.\n",
        "    rows = [row for row in rows if row]\n",
        "    # Split each row into columns using individual characters.\n",
        "    matrix = []\n",
        "    for row in rows:\n",
        "        columns = [char for char in row]\n",
        "        matrix.append(columns)\n",
        "\n",
        "    # Return the resulting matrix.\n",
        "    return matrix\n",
        "def replace_characters(matrix):\n",
        "    # Define the characters to replace and their replacements.\n",
        "    replacements = {'\\\\': '/', '&':'-'}\n",
        "    #  Create a new matrix to store the modified elements.\n",
        "    new_matrix = []\n",
        "    for row in matrix:\n",
        "        new_row = []\n",
        "        for element in row:\n",
        "            # If the current element is in the replacements dictionary, replace it.\n",
        "            if element in replacements:\n",
        "                new_row.append(replacements[element])\n",
        "            else:\n",
        "                new_row.append(element)\n",
        "        new_matrix.append(new_row)\n",
        "\n",
        "    # Return the modified matrix.\n",
        "    return new_matrix\n",
        "def create_binary_matrices(matrix):\n",
        "    # Define the characters to search for in the matrix.\n",
        "    characters = {'X', '/', '#', '*', '^', '-'}\n",
        "\n",
        "    # Determine the dimensions of the matrix.\n",
        "    num_rows = len(matrix)\n",
        "    num_cols = len(matrix[0])\n",
        "\n",
        "    # Create a dictionary to store the binary matrices.\n",
        "    binary_matrices = {}\n",
        "\n",
        "    # Loop through each character and create a binary matrix for that character.\n",
        "    for character in characters:\n",
        "        # Create a NumPy array to store the binary matrix.\n",
        "        binary_matrix = np.zeros((num_rows, num_cols))\n",
        "\n",
        "        # Loop through each element in the matrix and set the corresponding\n",
        "        # element in the binary matrix to 1 if it matches the current character.\n",
        "        for i in range(num_rows):\n",
        "            for j in range(num_cols):\n",
        "                if matrix[i][j] == character:\n",
        "                    binary_matrix[i][j] = 1\n",
        "\n",
        "        # Add the binary matrix to the dictionary.\n",
        "        binary_matrices[character] = binary_matrix\n",
        "\n",
        "    # Return the dictionary of binary matrices.\n",
        "    return binary_matrices"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NRzOizf804tW",
        "outputId": "b9d0842a-68c8-4219-fc3e-87e18d64f52e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'X': 'block', '/': 'structure1', '\\\\': 'structure2', '#': 'Enemy', '*': 'switch', '^': 'spike', '-': 'food'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# mount files"
      ],
      "metadata": {
        "id": "ZqNLz8_ETDKt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title mounting files\n",
        "\n",
        "# extracting labels\n",
        "drive.mount('/content/drive')\n",
        "gram_dict = {}\n",
        "map_dict = {}\n",
        "ngram_dict = {}\n",
        "\n",
        "# gram elite info\n",
        "with open('/content/drive/MyDrive/DungeonData/gram_elites/generate_corpus_info.json') as f:\n",
        "    data = json.load(f)\n",
        "    for filename in data['fitness'].keys():\n",
        "      gram_dict[filename] = data['fitness'][filename]\n",
        "print(\"gram_elite_info.json imported\")\n",
        "\n",
        "# map elite info\n",
        "with open('/content/drive/MyDrive/DungeonData/map_elites/generate_corpus_info.json') as f:\n",
        "    data = json.load(f)\n",
        "    for filename in data['fitness'].keys():\n",
        "      map_dict[filename] = data['fitness'][filename]\n",
        "print(\"map_elites_info.json imported\")\n",
        "\n",
        "# n gram info\n",
        "with open('/content/drive/MyDrive/DungeonData/n_gram/generate_corpus_info.json') as f:\n",
        "    data = json.load(f)\n",
        "    for filename in data['fitness'].keys():\n",
        "      ngram_dict[filename] = data['fitness'][filename]\n",
        "print(\"ngram_info.json imported\")\n",
        "\n",
        "# extracting levels\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "playable_level_strings = []\n",
        "unplayable_level_strings = []\n",
        "playable_level_labels = []\n",
        "unplayable_level_labels = []\n",
        "\n",
        "#gram elite\n",
        "for filename in os.listdir('/content/drive/MyDrive/DungeonData/gram_elites/levels'):\n",
        "  if filename.endswith('.txt'):\n",
        "      with open(os.path.join('/content/drive/MyDrive/DungeonData/gram_elites/levels', filename), 'r') as file:\n",
        "          file_contents = file.read()\n",
        "          if filename in gram_dict:\n",
        "            if gram_dict[filename] != 0:\n",
        "              playable_level_strings.append(file_contents)\n",
        "              playable_level_labels.append(1)\n",
        "            else:\n",
        "              unplayable_level_strings.append(file_contents)\n",
        "              unplayable_level_labels.append(0)\n",
        "print(\"gram elite levels imported\")\n",
        "\n",
        "#map elite\n",
        "for filename in os.listdir('/content/drive/MyDrive/DungeonData/map_elites/levels'):\n",
        "  if filename.endswith('.txt'):\n",
        "      with open(os.path.join('/content/drive/MyDrive/DungeonData/map_elites/levels', filename), 'r') as file:\n",
        "          file_contents = file.read()\n",
        "          if filename in map_dict:\n",
        "            if map_dict[filename] != 0:\n",
        "              playable_level_strings.append(file_contents)\n",
        "              playable_level_labels.append(1)\n",
        "            else:\n",
        "              unplayable_level_strings.append(file_contents)\n",
        "              unplayable_level_labels.append(0)\n",
        "print(\"map elite levels imported\")\n",
        "\n",
        "#n gram\n",
        "for filename in os.listdir('/content/drive/MyDrive/DungeonData/n_gram/levels'):\n",
        "  if filename.endswith('.txt'):\n",
        "      with open(os.path.join('/content/drive/MyDrive/DungeonData/n_gram/levels', filename), 'r') as file:\n",
        "          file_contents = file.read()\n",
        "          if filename in ngram_dict:\n",
        "            if ngram_dict[filename] != 0:\n",
        "              playable_level_strings.append(file_contents)\n",
        "              playable_level_labels.append(1)\n",
        "            else:\n",
        "              unplayable_level_strings.append(file_contents)\n",
        "              unplayable_level_labels.append(0)\n",
        "print(\"n gram levels imported\")"
      ],
      "metadata": {
        "id": "d45KH3tp0kLn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title balance the dataset\n",
        "from imblearn.over_sampling import ADASYN\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "\n",
        "\n",
        "#print(\"number of playable levels before balancing : %4d| number of unplayable levels before balancing : %4d|\" % (len(playable_level_strings), len(unplayable_level_strings)))\n",
        "# Reshape X to a 2D array\n",
        "#X_flat = np.reshape(levels, (levels.shape[0], -1))\n",
        "# Reshape y to a 2D array\n",
        "#y_flat = np.reshape(labels, (-1, 1))\n",
        "#oversampler = RandomUnderSampler()\n",
        "#X_resampled_flat, y_resampled_flat = oversampler.fit_resample(X_flat, y_flat)\n",
        "# Reshape the 2D array back to the original shape\n",
        "#X_resampled = np.reshape(X_resampled_flat, (-1, levels.shape[1], levels.shape[2], levels.shape[3]))\n",
        "# Reshape the y 2D array back to the original shape\n",
        "#y_resampled = np.reshape(y_resampled_flat, (-1,))\n",
        "\n",
        "#print(X_resampled.shape)\n",
        "#print(y_resampled.shape)\n",
        "#print(\"number of playable levels after balancing : %4d| number of unplayable levels after balancing : %4d|\" % (np.count_nonzero(y_resampled == 0), np.count_nonzero(y_resampled == 1)))\n",
        "# balance the dataset\n",
        "print(\"number of playable levels before balancing : %4d| number of unplayable levels before balancing : %4d|\" % (len(playable_level_strings), len(unplayable_level_strings)))\n",
        "n = len(unplayable_level_strings) - len(playable_level_strings)\n",
        "for i in range(n):\n",
        "    index = random.randint(0, len(unplayable_level_strings)-1)\n",
        "    unplayable_level_strings.pop(index)\n",
        "    unplayable_level_labels.pop(index)\n",
        "print(\"number of playable levels after balancing : %4d| number of unplayable levels after balancing : %4d|\" % (len(playable_level_strings), len(unplayable_level_strings)))\n"
      ],
      "metadata": {
        "id": "GeX21p4P0pmj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title convert level strings to one-hot matrices\n",
        "\n",
        "#@title convert level strings to one-hot matrices\n",
        "print(len(playable_level_strings))\n",
        "print(len(unplayable_level_strings))\n",
        "level_strings = []\n",
        "level_strings.extend(playable_level_strings)\n",
        "level_strings.extend(unplayable_level_strings)\n",
        "labels = []\n",
        "labels.extend(playable_level_labels)\n",
        "labels.extend(unplayable_level_labels)\n",
        "labels = np.array(labels)\n",
        "\n",
        "playable_idx = np.random.choice(range(len(playable_level_strings)), size=5, replace=False)\n",
        "unplayable_idx = np.random.choice(range(len(unplayable_level_strings)), size=5, replace=False)\n",
        "initial_x = []\n",
        "initial_y = []\n",
        "\n",
        "for i in playable_idx:\n",
        "  matrix = create_matrix(playable_level_strings[i])\n",
        "  replaced = replace_characters(matrix)\n",
        "  binary = create_binary_matrices(replaced)\n",
        "  initial_x.append(np.array(list(binary.values())))\n",
        "  initial_y.append(1)\n",
        "\n",
        "for i in playable_idx:\n",
        "  matrix = create_matrix(playable_level_strings[i])\n",
        "  replaced = replace_characters(matrix)\n",
        "  binary = create_binary_matrices(replaced)\n",
        "  initial_x.append(np.array(list(binary.values())))\n",
        "  initial_y.append(0)\n",
        "\n",
        "# Define the size of the level\n",
        "# Split the level into individual rows\n",
        "rows = level_strings[0].strip().split('\\n')\n",
        "# Find the width and height of the level\n",
        "width = len(rows)\n",
        "height = len(rows[0])\n",
        "num_levels = len(level_strings)\n",
        "levels = np.zeros((num_levels, 6,width,height))\n",
        "\n",
        "for i, level_string in enumerate(level_strings):\n",
        "    matrix = create_matrix(level_string)\n",
        "    replaced = replace_characters(matrix)\n",
        "    binary = create_binary_matrices(replaced)\n",
        "    levels[i] = np.array(list(binary.values()))\n",
        "print('the overal shape of X dataset: ' + str(levels.shape))\n",
        "print('the overal shape of Y dataset: ' + str(labels.shape))"
      ],
      "metadata": {
        "id": "JtEAXNRr0nMG",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model"
      ],
      "metadata": {
        "id": "TNupNSnTTNaB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class Model(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Model, self).__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(6, 16, kernel_size=3, padding=1)\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.pool1 = nn.MaxPool2d(kernel_size=2)\n",
        "\n",
        "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, padding=1)\n",
        "        self.relu2 = nn.ReLU()\n",
        "        self.pool2 = nn.MaxPool2d(kernel_size=2)\n",
        "\n",
        "        self.conv3 = nn.Conv2d(32, 64, kernel_size=2, padding=0)\n",
        "        self.relu3 = nn.ReLU()\n",
        "\n",
        "        self.fc1 = nn.Linear(128, 32)\n",
        "        self.relu4 = nn.ReLU()\n",
        "\n",
        "        self.fc2 = nn.Linear(32, 2)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.relu1(x)\n",
        "        x = self.pool1(x)\n",
        "\n",
        "        x = self.conv2(x)\n",
        "        x = self.relu2(x)\n",
        "        x = self.pool2(x)\n",
        "\n",
        "        x = self.conv3(x)\n",
        "        x = self.relu3(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "\n",
        "        x = self.fc1(x)\n",
        "        x = self.relu4(x)\n",
        "\n",
        "        x = self.fc2(x)\n",
        "        x = self.sigmoid(x)\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "NjtqR9FP1zkp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Passive Learner"
      ],
      "metadata": {
        "id": "KqICOaIYTX1B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import time\n",
        "\n",
        "def encode_labels(labels):\n",
        "    if not isinstance(labels, torch.Tensor) or labels.dtype != torch.float32:\n",
        "        raise ValueError(\"Input must be a PyTorch tensor of float32 dtype.\")\n",
        "    if labels.ndim != 1 or not torch.all(torch.logical_or(labels == 0, labels == 1)):\n",
        "        raise ValueError(\"Input must be a 1D PyTorch tensor of 0s and 1s.\")\n",
        "    encoded_labels = torch.zeros((len(labels), 2), dtype=torch.float32)\n",
        "    encoded_labels[torch.where(labels == 0)[0], 0] = 1\n",
        "    encoded_labels[torch.where(labels == 1)[0], 1] = 1\n",
        "    return encoded_labels\n",
        "\n",
        "X_tensor = torch.FloatTensor(levels)\n",
        "y_tensor = torch.FloatTensor(labels)\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "dataset = torch.utils.data.TensorDataset(torch.tensor(X_tensor).to(device), torch.tensor(y_tensor).to(device))\n",
        "# Assign 20% of the data to the validation set\n",
        "train_data, test_data = train_test_split(dataset, test_size=0.2, random_state=42)\n",
        "\n",
        "#uncomment if want\n",
        "# Assign 20% of the data to the validation set\n",
        "#trainval_data, test_data = train_test_split(dataset, test_size=0.2, random_state=42)\n",
        "# Assign 600 random samples of the dataset to the training set\n",
        "#train_data, val_data = torch.utils.data.random_split(trainval_data, [600, len(trainval_data) - 600])\n",
        "\n",
        "print(len(test_data))\n",
        "print(len(train_data))\n",
        "\n",
        "# Define the number of folds for cross-validation on the validation set\n",
        "num_folds = 5\n",
        "\n",
        "# Use scikit-learn's KFold to split the validation set into folds\n",
        "kf = KFold(n_splits=num_folds, shuffle=True)\n",
        "\n",
        "\n",
        "# Initialize lists to accumulate the true and predicted labels for all folds\n",
        "all_true_labels = []\n",
        "all_pred_labels = []\n",
        "all_fold_acc_history = []\n",
        "start_time = time.time()\n",
        "\n",
        "# Iterate over the folds on the validation set\n",
        "for fold, (train_indices, val_indices) in enumerate(kf.split(test_data)):\n",
        "\n",
        "    # Create a new instance of your model for each fold\n",
        "    model = Model()\n",
        "    criterion = nn.BCELoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), weight_decay=0.01)\n",
        "\n",
        "    # Create DataLoader objects for the training and validation sets for this fold\n",
        "    train_fold_data = torch.utils.data.Subset(train_data, train_indices)\n",
        "    val_fold_data = torch.utils.data.Subset(test_data, val_indices)\n",
        "    train_fold_loader = torch.utils.data.DataLoader(train_fold_data, batch_size=len(train_fold_data), shuffle=True)\n",
        "    val_fold_loader = torch.utils.data.DataLoader(val_fold_data, batch_size=len(val_fold_data), shuffle=True)\n",
        "\n",
        "    fold_acc_history = []\n",
        "    # Train the model for this fold\n",
        "    for epoch in range(100):\n",
        "        train_loss = 0\n",
        "        train_acc = 0\n",
        "        for inputs, labels in train_fold_loader:\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, encode_labels(labels))\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            train_loss += loss.item()\n",
        "        train_loss /= len(val_fold_loader)\n",
        "        # Print the training loss and accuracy for this epoch\n",
        "        print(f\"Validation fold {fold + 1}, epoch {epoch + 1}: train_loss = {train_loss:.2f}\")\n",
        "\n",
        "# Evaluate the model on the validation set for this fold\n",
        "        with torch.no_grad():\n",
        "            model.eval()\n",
        "            val_loss = 0\n",
        "            val_acc = 0\n",
        "            true_labels = []\n",
        "            pred_labels = []\n",
        "            for inputs, labels in val_fold_loader:\n",
        "                outputs = model(inputs)\n",
        "                loss = criterion(outputs, encode_labels(labels))\n",
        "                val_loss += loss.item()\n",
        "                y_pred = np.argmax(outputs, axis=1)\n",
        "                true_labels += labels.tolist()\n",
        "                pred_labels += y_pred.round().tolist()\n",
        "            val_loss /= len(val_fold_loader)\n",
        "\n",
        "        # Print the validation loss and accuracy for this fold\n",
        "        val_acc = accuracy_score(true_labels, pred_labels)\n",
        "        fold_acc_history.append(val_acc)\n",
        "        # Print the validation loss and accuracy for this fold\n",
        "        print(f\"Fold {fold + 1}: val_loss = {val_loss:.2f}, val_acc = {val_acc:.2f}\")\n",
        "        # Add the accuracy history for this fold to the list of all fold accuracy histories\n",
        "    if(np.mean(fold_acc_history) > 0.5) :\n",
        "        all_fold_acc_history.append(fold_acc_history)\n",
        "        # Accumulate the true and predicted labels for all folds\n",
        "        all_true_labels += true_labels\n",
        "        all_pred_labels += pred_labels\n",
        "\n",
        "# Compute the overall confusion matrix and accuracy\n",
        "overall_cm = confusion_matrix(all_true_labels, all_pred_labels)\n",
        "overall_acc = accuracy_score(all_true_labels, all_pred_labels)\n",
        "\n",
        "# Print the overall confusion matrix and accuracy\n",
        "print(f\"Overall confusion matrix:\\n{overall_cm}\")\n",
        "print(f\"Overall accuracy: {overall_acc:.2f}\")\n",
        "\n",
        "# Compute the average accuracy over all folds for each epoch\n",
        "mean_acc_history = [sum([fold_acc_history[i] for fold_acc_history in all_fold_acc_history])/num_folds for i in range(len(all_fold_acc_history[0]))]\n",
        "\n",
        "# Plot the average accuracy over all folds over time\n",
        "plt.plot(mean_acc_history)\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Average Accuracy over Time')\n",
        "plt.show()\n",
        "end_time = time.time()\n",
        "execution_time = end_time - start_time\n",
        "print(f\"Execution time of: {execution_time} seconds\")\n",
        "\n",
        "import pickle\n",
        "\n",
        "with open('/content/drive/MyDrive/Zelda-data/passive-accuracy-400-last.pickle', 'wb') as handle:\n",
        "    pickle.dump(all_fold_acc_history, handle)\n",
        "\n",
        "with open('/content/drive/MyDrive/Zelda-data/passive-confusion-400-last.pickle', 'wb') as handle:\n",
        "    pickle.dump(overall_cm, handle)\n",
        "\n",
        "with open('/content/drive/MyDrive/Zelda-data/passive-execution-400-last.pickle', 'wb') as handle:\n",
        "    pickle.dump(execution_time, handle)\n"
      ],
      "metadata": {
        "id": "wDeAfed8kEJa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Active Learner"
      ],
      "metadata": {
        "id": "7tfJ0UuyTSt0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def random_query_strategy(classifier, X, n_instances=1):\n",
        "    # Generate a list of indices to select random instances from X\n",
        "    indices = list(range(len(X)))\n",
        "    # Shuffle the indices to select random instances\n",
        "    random.shuffle(indices)\n",
        "    # Return the first n_instances instances from the shuffled indices\n",
        "    return indices[:n_instances]\n",
        "\n",
        "#random_query_strategy\n",
        "#margin_sampling\n",
        "#entropy_sampling\n",
        "#uncertainty_sampling"
      ],
      "metadata": {
        "id": "qE2oX3YH2D03"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title active learner\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import pdb\n",
        "import math\n",
        "import time\n",
        "\n",
        "#random_query_strategy\n",
        "#margin_sampling\n",
        "#entropy_sampling\n",
        "#uncertainty_sampling\n",
        "\n",
        "def train_active_learner(strategy, n_queries, n_instances, max_epochs):\n",
        "    # Use scikit-learn's KFold to split the validation set into folds\n",
        "    num_folds = 5\n",
        "    kf = KFold(n_splits=num_folds, shuffle=True)\n",
        "    # Initialize lists to accumulate the true and predicted labels for all folds\n",
        "    all_fold_acc_history = []\n",
        "    avg_false_positives = []\n",
        "    avg_false_negatives = []\n",
        "    all_c = []\n",
        "    # Create DataLoader objects for the training and validation sets for this fold\n",
        "    X_tensor = torch.FloatTensor(levels)\n",
        "    y_tensor = torch.LongTensor(labels)\n",
        "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "    dataset = torch.utils.data.TensorDataset(torch.tensor(X_tensor).to(device), torch.tensor(y_tensor).to(device))\n",
        "    dataset_loader = torch.utils.data.DataLoader(dataset, batch_size=len(dataset))\n",
        "    X , y = next(iter(dataset_loader))\n",
        "    X = X.detach().cpu().numpy()\n",
        "    y = y.detach().cpu().numpy()\n",
        "\n",
        "    X_ini = torch.FloatTensor(initial_x)\n",
        "    y_ini = torch.LongTensor(initial_y)\n",
        "    ini_dataset = torch.utils.data.TensorDataset(torch.tensor(X_ini).to(device), torch.tensor(y_ini).to(device))\n",
        "    ini_loader = torch.utils.data.DataLoader(ini_dataset, batch_size=len(ini_dataset))\n",
        "    X_0 , y_0 = next(iter(ini_loader))\n",
        "    X_0 = X_0.detach().cpu().numpy()\n",
        "    y_0 = y_0.detach().cpu().numpy()\n",
        "\n",
        "    # initialize ActiveLearner\n",
        "    #n_initial = 10\n",
        "    #initial_idx = np.random.choice(range(len(dataset)), size=n_initial, replace=False)\n",
        "    #data_initial = torch.utils.data.Subset(dataset, initial_idx)\n",
        "    #data_initial_loader = torch.utils.data.DataLoader(data_initial, batch_size=len(data_initial))\n",
        "    #X_0 , y_0 = next(iter(data_initial_loader))\n",
        "    #X_0 = X_0.detach().cpu().numpy()\n",
        "    #y_0 = y_0.detach().cpu().numpy()\n",
        "\n",
        "    # Iterate over the folds on the validation set\n",
        "    start_time = time.time()\n",
        "    for fold, (train_indices, val_indices) in enumerate(kf.split(dataset)):\n",
        "        X_train = X[train_indices]\n",
        "        X_test= X[val_indices]\n",
        "        y_train = y[train_indices]\n",
        "        y_test = y[val_indices]\n",
        "        false_negatives = []\n",
        "        false_positives = []\n",
        "\n",
        "        print(f\"Fold no {fold+1}\")\n",
        "        # Create a new instance of your model for each fold\n",
        "        classifier = NeuralNetClassifier(Model,\n",
        "                                 criterion=nn.CrossEntropyLoss,\n",
        "                                 optimizer=torch.optim.Adam,\n",
        "                                 optimizer__weight_decay=0.01,\n",
        "                                 max_epochs = max_epochs,\n",
        "                                 train_split=None,\n",
        "                                 verbose=0,\n",
        "                                 device=device,\n",
        "                                 warm_start = True,\n",
        "                                 )\n",
        "        learner = ActiveLearner(estimator=classifier,X_training=X_0, y_training=y_0,query_strategy=strategy)\n",
        "        y_pred = learner.predict(X_test)\n",
        "        ini_acc = accuracy_score(y_test, y_pred)\n",
        "        print(ini_acc)\n",
        "        fold_acc_history = []\n",
        "        #trained_x = np.empty((0,8,14,25))\n",
        "        #trained_y = np.empty((0,))\n",
        "\n",
        "        for idx in range(n_queries):\n",
        "              false_positives = 0\n",
        "              false_negatives = 0\n",
        "              fold_fn = []\n",
        "              fold_fp = []\n",
        "            #for k in range(0,5):\n",
        "              random_indices = np.random.choice(range(len(X_train)), size=math.floor(0.5*len(X_train)), replace=False)\n",
        "\n",
        "              query_idx, query_instance = learner.query(X_train[random_indices], n_instances=n_instances)\n",
        "              #print(\"query length \", len(query_idx))\n",
        "              '''\n",
        "              if idx == 0:\n",
        "                trained_x = x_query\n",
        "                trained_y = y_query\n",
        "              else:\n",
        "                trained_x = np.append(trained_x,x_query, axis=0)\n",
        "                trained_y = np.append(trained_y,y_query, axis = 0)\n",
        "              #print(\"trained length: \", len(trained_x))\n",
        "              learner.teach(X=trained_x, y=trained_y)\n",
        "              '''\n",
        "              x_query = X_train[query_idx]\n",
        "              y_query = y_train[query_idx]\n",
        "              learner.teach(X=x_query, y=y_query)\n",
        "              # Evaluate the performance of the active learning model\n",
        "              y_pred = learner.predict(X_test)\n",
        "              true_labels = y_test.tolist()\n",
        "              pred_labels = y_pred.tolist()\n",
        "              # Compute FP and FN\n",
        "\n",
        "              #false_positives = np.count_nonzero(np.logical_and((pred_labels == 1),(true_labels == 0)))\n",
        "              #false_negatives = np.count_nonzero(np.logical_and((pred_labels == 0),(true_labels == 1)))\n",
        "              #pdb.set_trace()\n",
        "              val_acc = accuracy_score(y_test, y_pred)\n",
        "              fold_acc_history.append(val_acc)\n",
        "              # remove queried instance from pool\n",
        "              X_train = np.delete(X_train, query_idx, axis=0)\n",
        "              y_train = np.delete(y_train, query_idx, axis=0)\n",
        "              print(f\"Query no {idx+1}: Acc = {val_acc:.2f}:\")\n",
        "              #fold_fn.append(false_negatives)\n",
        "              #fold_fp.append(false_positives)\n",
        "              #c = confusion_matrix(true_labels, pred_labels)\n",
        "\n",
        "        for kk in range(len(true_labels)):\n",
        "                if (pred_labels[kk] == 1) & (true_labels[kk] == 0):\n",
        "                  false_positives += 1\n",
        "                if (pred_labels[kk] == 0) & (true_labels[kk] == 1):\n",
        "                  false_negatives += 1\n",
        "        c = confusion_matrix(true_labels, pred_labels)\n",
        "        #if np.mean(np.array(fold_acc_history))>0.51:\n",
        "        all_fold_acc_history.append(fold_acc_history)\n",
        "          # Compute the average FP and FN for all folds\n",
        "        #avg_false_positives.append(fold_fp)\n",
        "        #avg_false_negatives.append(fold_fn)\n",
        "        all_c.append(c)\n",
        "\n",
        "    # Compute the overall confusion matrix and accuracy\n",
        "    #overall_cm = confusion_matrix(all_true_labels, all_pred_labels)\n",
        "    #overall_acc = accuracy_score(all_true_labels, all_pred_labels)\n",
        "\n",
        "    # Compute the average accuracy over all folds for each epoch\n",
        "    #mean_acc_history = [sum([fold_acc_history[i] for fold_acc_history in all_fold_acc_history])/num_folds for i in range(len(all_fold_acc_history[0]))]\n",
        "    #mean_acc_history = [ini_acc] + mean_acc_history\n",
        "    end_time = time.time()\n",
        "    execution_time = end_time - start_time\n",
        "\n",
        "    return  all_fold_acc_history , execution_time , all_c\n",
        "\n"
      ],
      "metadata": {
        "id": "7TJfSs6t2L1L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title margin sampling\n",
        "import pickle\n",
        "\n",
        "STRATEGY = margin_sampling\n",
        "N_INSTANCES = 1\n",
        "N_QUERIES = 400\n",
        "MAX_EPOCHS = 50\n",
        "np.random.seed(60)\n",
        "\n",
        "# Define the size of the level\n",
        "width = 29\n",
        "height = 13\n",
        "num_levels = len(level_strings)\n",
        "levels = np.zeros((num_levels, 6,11,15))\n",
        "\n",
        "for i, level_string in enumerate(level_strings):\n",
        "    matrix = create_matrix(level_string)\n",
        "    replaced = replace_characters(matrix)\n",
        "    binary = create_binary_matrices(replaced)\n",
        "    levels[i] = np.array(list(binary.values()))\n",
        "labels = []\n",
        "labels.extend(playable_level_labels)\n",
        "labels.extend(unplayable_level_labels)\n",
        "labels = np.array(labels)\n",
        "print('the overal shape of X dataset: ' + str(levels.shape))\n",
        "print('the overal shape of Y dataset: ' + str(labels.shape))\n",
        "\n",
        "all_fold_acc_history_1, execution_time_1, overall_cm_1= train_active_learner(STRATEGY, N_QUERIES, N_INSTANCES,MAX_EPOCHS)\n",
        "\n",
        "print(f\"Execution time: {execution_time_1} seconds\")\n",
        "print(f\"confusion matrix: {overall_cm_1}\")\n",
        "\n",
        "# Extract false positives and false negatives from each matrix\n",
        "fps = [np.mean(cm[0][1]) for cm in overall_cm_1]\n",
        "fns = [np.mean(cm[1][0]) for cm in overall_cm_1]\n",
        "\n",
        "print(fps)\n",
        "print(fns)\n",
        "\n",
        "# Calculate average accuracy and standard error for each epoch\n",
        "mean_accuracy_1 = np.mean(all_fold_acc_history_1, axis=0)\n",
        "std_error_1 = np.std(all_fold_acc_history_1, axis=0) / np.sqrt(len(all_fold_acc_history_1))\n",
        "std_dev_1 = np.std(all_fold_acc_history_1, axis=0)\n",
        "# Plotting\n",
        "epochs_1 = range(1, len(mean_accuracy_1) + 1)\n",
        "# Calculate upper and lower bounds for the fill region\n",
        "lower_bound_1 = mean_accuracy_1 - std_dev_1\n",
        "upper_bound_1 = mean_accuracy_1 + std_dev_1\n",
        "\n",
        "plt.errorbar(epochs_1, mean_accuracy_1, yerr=std_error_1, capsize=3)\n",
        "plt.xlabel('Queries')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Average Accuracy over Epoch with Standard Error')\n",
        "plt.show()\n",
        "\n",
        "plt.plot(epochs_1, mean_accuracy_1, label='Average Accuracy')\n",
        "plt.fill_between(epochs_1, lower_bound_1, upper_bound_1, alpha=0.3, label='Standard Deviation')\n",
        "plt.xlabel('Queries')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Average Accuracy over Queries with Standard Deviation')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "with open('/content/drive/MyDrive/Zelda-data/margin-accuracy-400-last.pickle', 'wb') as handle:\n",
        "    pickle.dump(all_fold_acc_history_1, handle)\n",
        "\n",
        "with open('/content/drive/MyDrive/Zelda-data/margin-confusion-400-last.pickle', 'wb') as handle:\n",
        "    pickle.dump(overall_cm_1, handle)\n",
        "\n",
        "with open('/content/drive/MyDrive/Zelda-data/margin-execution-400-last.pickle', 'wb') as handle:\n",
        "    pickle.dump(execution_time_1, handle)"
      ],
      "metadata": {
        "id": "ED2k_3vV2Rgx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title random sampling\n",
        "STRATEGY = random_query_strategy\n",
        "N_INSTANCES = 1\n",
        "N_QUERIES = 400\n",
        "MAX_EPOCHS = 50\n",
        "np.random.seed(50)\n",
        "\n",
        "# Define the size of the level\n",
        "width = 29\n",
        "height = 13\n",
        "num_levels = len(level_strings)\n",
        "levels = np.zeros((num_levels, 6,11,15))\n",
        "\n",
        "for i, level_string in enumerate(level_strings):\n",
        "    matrix = create_matrix(level_string)\n",
        "    replaced = replace_characters(matrix)\n",
        "    binary = create_binary_matrices(replaced)\n",
        "    levels[i] = np.array(list(binary.values()))\n",
        "labels = []\n",
        "labels.extend(playable_level_labels)\n",
        "labels.extend(unplayable_level_labels)\n",
        "labels = np.array(labels)\n",
        "print('the overal shape of X dataset: ' + str(levels.shape))\n",
        "print('the overal shape of Y dataset: ' + str(labels.shape))\n",
        "\n",
        "all_fold_acc_history_2, execution_time_2, overall_cm_2 = train_active_learner(STRATEGY, N_QUERIES, N_INSTANCES,MAX_EPOCHS)\n",
        "print(f\"Execution time: {execution_time_2} seconds\")\n",
        "print(f\"confusion matrix: {overall_cm_2}\")\n",
        "# Extract false positives and false negatives from each matrix\n",
        "fps = [np.mean(cm[0][1]) for cm in overall_cm_1]\n",
        "fns = [np.mean(cm[1][0]) for cm in overall_cm_1]\n",
        "\n",
        "print(fps)\n",
        "print(fns)\n",
        "# Calculate average accuracy and standard error for each epoch\n",
        "mean_accuracy_2 = np.mean(all_fold_acc_history_2, axis=0)\n",
        "std_error_2 = np.std(all_fold_acc_history_2, axis=0) / np.sqrt(len(all_fold_acc_history_2))\n",
        "std_dev_2 = np.std(all_fold_acc_history_2, axis=0)\n",
        "# Plotting\n",
        "epochs_2 = range(1, len(mean_accuracy_2) + 1)\n",
        "# Calculate upper and lower bounds for the fill region\n",
        "lower_bound_2 = mean_accuracy_2 - std_dev_2\n",
        "upper_bound_2 = mean_accuracy_2 + std_dev_2\n",
        "\n",
        "plt.errorbar(epochs_2, mean_accuracy_2, yerr=std_error_2, capsize=3)\n",
        "plt.xlabel('Queries')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Average Accuracy over Epoch with Standard Error')\n",
        "plt.show()\n",
        "\n",
        "plt.plot(epochs_2, mean_accuracy_2, label='Average Accuracy')\n",
        "plt.fill_between(epochs_2, lower_bound_2, upper_bound_2, alpha=0.3, label='Standard Deviation')\n",
        "plt.xlabel('Queries')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Average Accuracy over Queries with Standard Deviation')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "with open('/content/drive/MyDrive/Zelda-data/random-accuracy-400-last.pickle', 'wb') as handle:\n",
        "    pickle.dump(all_fold_acc_history_2, handle)\n",
        "\n",
        "with open('/content/drive/MyDrive/Zelda-data/random-confusion-400-last.pickle', 'wb') as handle:\n",
        "    pickle.dump(overall_cm_2, handle)\n",
        "\n",
        "with open('/content/drive/MyDrive/Zelda-data/random-execution-400-last.pickle', 'wb') as handle:\n",
        "    pickle.dump(execution_time_2, handle)\n",
        "\n"
      ],
      "metadata": {
        "id": "thLAxjUD2W9k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# plots"
      ],
      "metadata": {
        "id": "huNQ9xKSTl0t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "print(len(all_fold_acc_history_2))\n",
        "epochs_1 = range(11, len(mean_accuracy_1) + 11)\n",
        "epochs_2 = range(11, len(mean_accuracy_1) + 11)\n",
        "\n",
        "plt.plot(epochs_1, mean_accuracy_1, color='b', linestyle='-', label='Uncertainty Sampling')\n",
        "plt.fill_between(epochs_1, lower_bound_1, upper_bound_1, alpha=0.3)\n",
        "plt.plot(epochs_2, mean_accuracy_2,color='r', linestyle='-', label='Random Sampling')\n",
        "plt.fill_between(epochs_2, lower_bound_2, upper_bound_2, alpha=0.3)\n",
        "plt.axhline(y=0.81, color='g', linestyle='--', label=\"Passive Learner (1206 samples)\")\n",
        "plt.ylim(0.4, 1)\n",
        "plt.xlim(10, 410)\n",
        "plt.xlabel('#Samples')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Average Accuracy over Samples')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "\n",
        "plt.plot(epochs_1, mean_accuracy_1, color='b', linestyle='-', label='Uncertainty Sampling')\n",
        "plt.fill_between(epochs_1, lower_bound_1, upper_bound_1, alpha=0.3)\n",
        "plt.plot(epochs_2, mean_accuracy_2,color='r', linestyle='-', label='Random Sampling')\n",
        "plt.fill_between(epochs_2, lower_bound_2, upper_bound_2, alpha=0.3)\n",
        "plt.axhline(y=0.81, color='g', linestyle='--', label=\"Passive Learner (1206 samples)\")\n",
        "plt.xlabel('#Samples')\n",
        "plt.ylabel('Accuracy')\n",
        "#plt.xticks(np.arange(10,410, 50))\n",
        "plt.title('Average Accuracy over Samples')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "WXQeykBv33Jf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}