{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP6hRTNULu5+lYGKtfNNg1I"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Setup"
      ],
      "metadata": {
        "id": "dn7pabGdIpOe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/modAL-python/modAL.git\n",
        "!pip install ipdb"
      ],
      "metadata": {
        "id": "vCN-3R9jF5BB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Jd4tZnsr5Pu"
      },
      "outputs": [],
      "source": [
        "#@title import libraries\n",
        "from google.colab import drive\n",
        "import json\n",
        "import os\n",
        "import random\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import pdb\n",
        "from modAL.models import ActiveLearner\n",
        "from modAL.uncertainty import uncertainty_sampling\n",
        "from modAL.uncertainty import margin_sampling\n",
        "from modAL.uncertainty import entropy_sampling\n",
        "from skorch import NeuralNetClassifier\n",
        "from skorch.callbacks import Callback\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from torchvision.transforms import ToTensor\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import KFold\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Utility Functions"
      ],
      "metadata": {
        "id": "8WTzgIqpI-OK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_value(input):\n",
        "  #51  53  56  62  66  70  80  (85  86  87  88  89  90  91  92  93  94 95  96  98  99 100 101 104 105 106 109 110 111 112 113 114 117]\n",
        "  if input in range(51,53): #empty\n",
        "    return 1\n",
        "  elif input in range(53,66): #enemy\n",
        "    return 2\n",
        "  elif input in range(66,80): #door\n",
        "    return 3\n",
        "  elif input in range (80,86): #key\n",
        "    return 4\n",
        "  elif input in range (88,92): #player\n",
        "    return 6\n",
        "  elif input in range (86,88) or (92,120): #wall\n",
        "    return 5\n"
      ],
      "metadata": {
        "id": "_4uuEmVRml3D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Mount Resources"
      ],
      "metadata": {
        "id": "rB6ZBh9yIy1n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')\n",
        "# Define the border size\n",
        "map_border = 60\n",
        "tile_border = 0.5\n",
        "# Define the tile size\n",
        "tile_width = 60\n",
        "tile_height = 60\n",
        "distinct_values = [51,53,56,62,66,80,86,90,106]\n",
        "#51 : empty, 53: enemy,bat, 56:enemy,scorpions, 62: enemy,spider, 66:door, 80:key, 86: wall, 90:player, 106: wall\n",
        "#51 : empty, 53,56,62: enemy, 66:door, 80:key, 86,106: wall, 90:player\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mb0Y_eLoNSEO",
        "outputId": "55f45f99-90c8-4fb1-f52c-6c34eb387b83"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title mounting playbale files\n",
        "playable_levels = []\n",
        "playable_levels_labels = []\n",
        "for filename in os.listdir('/content/drive/MyDrive/Ghost Lab/levels/zelda/playable'):\n",
        "    # Check if the file is an image\n",
        "    if filename.endswith('.jpg') or filename.endswith('.jpeg') or filename.endswith('.png'):\n",
        "        # Open the image file\n",
        "        img = Image.open(os.path.join('/content/drive/MyDrive/Ghost Lab/levels/zelda/playable', filename))\n",
        "        tile_ints = []\n",
        "        # Iterate over each tile in the tile map\n",
        "        for y in range(0, 7):\n",
        "          for x in range(0, 11):\n",
        "            # Calculate the coordinates of the current tile in the tile map\n",
        "            tile_x1 = map_border + x * (tile_width + 2*tile_border)\n",
        "            tile_y1 = map_border + y * (tile_height + 2*tile_border)\n",
        "            tile_x2 = tile_x1 + tile_width + 2*tile_border\n",
        "            tile_y2 = tile_y1 + tile_height + 2*tile_border\n",
        "            # Crop the border of the current tile\n",
        "            tile_cropped = img.crop((tile_x1, tile_y1, tile_x2, tile_y2))\n",
        "            # Convert the cropped tile image to grayscale and get the pixel values\n",
        "            tile_gray = tile_cropped.convert('L')\n",
        "            tile_pixels = list(tile_gray.getdata())\n",
        "            # Convert the pixel values to an integer value\n",
        "            tile_int = int(sum(tile_pixels) / len(tile_pixels))\n",
        "            tile_ints.append(get_value(tile_int))\n",
        "        if len(tile_ints) == 77:\n",
        "          arr = np.array(tile_ints)\n",
        "          # Reshape the array into a 2D array of size 7x11\n",
        "          arr = np.array(tile_ints).reshape((7, 11))\n",
        "          distinc = [1,2,3,4,5,6]\n",
        "          matrix_dict = {val: (arr == val).astype(int) for val in distinc}\n",
        "          for key in [1,2,3,4,5,6]:\n",
        "            if key not in matrix_dict:\n",
        "              matrix_dict[key] = np.zeros((7,11))\n",
        "\n",
        "          # Convert the dictionary of counts to a NumPy array\n",
        "          matrix_array = np.array([matrix_dict[val] for val in distinc])\n",
        "          playable_levels.append(matrix_array)\n",
        "          playable_levels_labels.append(1)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "S2tQdQsb_Y7_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title mounting unplaybale files\n",
        "unplayable_levels = []\n",
        "unplayable_levels_labels = []\n",
        "for filename in os.listdir('/content/drive/MyDrive/Ghost Lab/levels/zelda/unplayable'):\n",
        "    # Check if the file is an image\n",
        "    if filename.endswith('.jpg') or filename.endswith('.jpeg') or filename.endswith('.png'):\n",
        "        # Open the image file\n",
        "        img = Image.open(os.path.join('/content/drive/MyDrive/Ghost Lab/levels/zelda/unplayable', filename))\n",
        "        tile_ints = []\n",
        "        # Iterate over each tile in the tile map\n",
        "        for y in range(0, 7):\n",
        "          for x in range(0, 11):\n",
        "            # Calculate the coordinates of the current tile in the tile map\n",
        "            tile_x1 = map_border + x * (tile_width + 2*tile_border)\n",
        "            tile_y1 = map_border + y * (tile_height + 2*tile_border)\n",
        "            tile_x2 = tile_x1 + tile_width + 2*tile_border\n",
        "            tile_y2 = tile_y1 + tile_height + 2*tile_border\n",
        "            # Crop the border of the current tile\n",
        "            tile_cropped = img.crop((tile_x1, tile_y1, tile_x2, tile_y2))\n",
        "            # Convert the cropped tile image to grayscale and get the pixel values\n",
        "            tile_gray = tile_cropped.convert('L')\n",
        "            tile_pixels = list(tile_gray.getdata())\n",
        "            # Convert the pixel values to an integer value\n",
        "            tile_int = int(sum(tile_pixels) / len(tile_pixels))\n",
        "            tile_int = int(sum(tile_pixels) / len(tile_pixels))\n",
        "            tile_ints.append(get_value(tile_int))\n",
        "        if len(tile_ints) == 77:\n",
        "          arr = np.array(tile_ints)\n",
        "          # Reshape the array into a 2D array of size 7x11\n",
        "          arr = np.array(tile_ints).reshape((7, 11))\n",
        "          distinc = [1,2,3,4,5,6]\n",
        "          matrix_dict = {val: (arr == val).astype(int) for val in distinc}\n",
        "          for key in [1,2,3,4,5,6]:\n",
        "            if key not in matrix_dict:\n",
        "              matrix_dict[key] = np.zeros((7,11))\n",
        "\n",
        "          # Convert the dictionary of counts to a NumPy array\n",
        "          matrix_array = np.array([matrix_dict[val] for val in distinc])\n",
        "          unplayable_levels.append(matrix_array)\n",
        "          unplayable_levels_labels.append(0)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "PGLM7srgNHzr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title balance the dataset\n",
        "from imblearn.over_sampling import ADASYN\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "\n",
        "playable_idx = np.random.choice(range(len(playable_levels)), size=5, replace=False)\n",
        "unplayable_idx = np.random.choice(range(len(unplayable_levels)), size=5, replace=False)\n",
        "initial_x = []\n",
        "initial_y = []\n",
        "\n",
        "for i in playable_idx:\n",
        "  initial_x.append(playable_levels[i])\n",
        "  initial_y.append(playable_levels_labels[i])\n",
        "\n",
        "for i in unplayable_idx:\n",
        "  initial_x.append(unplayable_levels[i])\n",
        "  initial_y.append(unplayable_levels_labels[i])\n",
        "\n",
        "\n",
        "\n",
        "levels = []\n",
        "levels.extend(playable_levels)\n",
        "levels.extend(unplayable_levels)\n",
        "levels = np.array(levels)\n",
        "print(levels.shape)\n",
        "\n",
        "labels = []\n",
        "labels.extend(playable_levels_labels)\n",
        "labels.extend(unplayable_levels_labels)\n",
        "labels = np.array(labels)\n",
        "print(labels.shape)\n",
        "\n",
        "initial_x = np.array(initial_x)\n",
        "print(initial_x.shape)\n",
        "initial_y = np.array(initial_y)\n",
        "print(initial_y.shape)\n",
        "\n",
        "print('the overal shape of X dataset: ' + str(levels.shape))\n",
        "print('the overal shape of Y dataset: ' + str(labels.shape))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U1aBAh71OwTX",
        "outputId": "0091cdb3-b8b3-4bb3-ec35-372a03ab39cb",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2048, 6, 7, 11)\n",
            "(2048,)\n",
            "(10, 6, 7, 11)\n",
            "(10,)\n",
            "the overal shape of X dataset: (2048, 6, 7, 11)\n",
            "the overal shape of Y dataset: (2048,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model"
      ],
      "metadata": {
        "id": "H1Zy6R-LJa_3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.models as models\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class ResNet18Custom(nn.Module):\n",
        "    def __init__(self, num_channels=6, num_classes=2):\n",
        "        super(ResNet18Custom, self).__init__()\n",
        "        self.resnet = models.resnet18()\n",
        "        self.resnet.conv1 = nn.Conv2d(num_channels, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
        "        self.resnet.fc = nn.Linear(512, num_classes)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.resnet(x)\n",
        "        #x = self.sigmoid(x)\n",
        "        x = F.softmax(x, dim=1)\n",
        "        return x\n",
        "        #x = self.resnet(x)\n",
        "        #x = self.resnet.conv1(x)\n",
        "        #x = self.resnet.fc(x)\n",
        "        #return x\n",
        "\n",
        "class Model(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Model, self).__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(6, 16, kernel_size=2)\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.pool1 = nn.MaxPool2d(kernel_size=2)\n",
        "\n",
        "        self.conv2 = nn.Conv2d(16, 32, kernel_size=2)\n",
        "        self.relu2 = nn.ReLU()\n",
        "        self.pool2 = nn.MaxPool2d(kernel_size=2)\n",
        "\n",
        "        self.conv3 = nn.Conv2d(32, 64, kernel_size=1)\n",
        "        self.relu3 = nn.ReLU()\n",
        "\n",
        "        self.fc1 = nn.Linear(128, 32)\n",
        "        self.relu4 = nn.ReLU()\n",
        "\n",
        "        self.fc2 = nn.Linear(32, 2)\n",
        "        self.softmax = nn.Softmax(dim=1)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.relu1(x)\n",
        "        x = self.pool1(x)\n",
        "\n",
        "        x = self.conv2(x)\n",
        "        x = self.relu2(x)\n",
        "        x = self.pool2(x)\n",
        "\n",
        "        x = self.conv3(x)\n",
        "        x = self.relu3(x)\n",
        "\n",
        "        x = torch.flatten(x, 1)\n",
        "\n",
        "        x = self.fc1(x)\n",
        "        x = self.relu4(x)\n",
        "\n",
        "        x = self.fc2(x)\n",
        "        x = self.softmax(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "import torch.nn as nn\n",
        "\n",
        "class Model2(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Model2, self).__init__()\n",
        "\n",
        "        self.fc1 = nn.Linear(6*7*11, 128)\n",
        "        self.relu1 = nn.ReLU()\n",
        "\n",
        "        self.fc2 = nn.Linear(128, 256)\n",
        "        self.relu2 = nn.ReLU()\n",
        "\n",
        "        self.fc3 = nn.Linear(256, 1024)\n",
        "        self.relu3 = nn.ReLU()\n",
        "\n",
        "        self.fc4 = nn.Linear(1024, 32)\n",
        "        self.relu4 = nn.ReLU()\n",
        "\n",
        "        self.fc5 = nn.Linear(32, 2)\n",
        "        self.softmax = nn.Softmax(dim=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(x.size(0), -1)\n",
        "\n",
        "        x = self.fc1(x)\n",
        "        x = self.relu1(x)\n",
        "\n",
        "        x = self.fc2(x)\n",
        "        x = self.relu2(x)\n",
        "\n",
        "        x = self.fc3(x)\n",
        "        x = self.relu3(x)\n",
        "\n",
        "        x = self.fc4(x)\n",
        "        x = self.relu4(x)\n",
        "\n",
        "        x = self.fc5(x)\n",
        "        x = self.softmax(x)\n",
        "\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "frMXx7j-FgR_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Passive Learner"
      ],
      "metadata": {
        "id": "URGc4HqYJf_d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import time\n",
        "import pickle\n",
        "import ipdb\n",
        "\n",
        "def encode_labels(labels):\n",
        "    if not isinstance(labels, torch.Tensor) or labels.dtype != torch.float32:\n",
        "        raise ValueError(\"Input must be a PyTorch tensor of float32 dtype.\")\n",
        "    if labels.ndim != 1 or not torch.all(torch.logical_or(labels == 0, labels == 1)):\n",
        "        raise ValueError(\"Input must be a 1D PyTorch tensor of 0s and 1s.\")\n",
        "    encoded_labels = torch.zeros((len(labels), 2), dtype=torch.float32)\n",
        "    encoded_labels[torch.where(labels == 0)[0], 0] = 1\n",
        "    encoded_labels[torch.where(labels == 1)[0], 1] = 1\n",
        "    return encoded_labels\n",
        "\n",
        "X_tensor = torch.FloatTensor(levels)\n",
        "y_tensor = torch.FloatTensor(labels)\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "dataset = torch.utils.data.TensorDataset(torch.tensor(X_tensor).to(device), torch.tensor(y_tensor).to(device))\n",
        "train_data, test_data = train_test_split(dataset, test_size=0.2, random_state=42)\n",
        "\n",
        "print(len(test_data))\n",
        "print(len(train_data))\n",
        "\n",
        "num_folds = 5\n",
        "num_epochs = 50\n",
        "weight_decay=1e-3 # reasonale 1e-4 to 1e-2.\n",
        "learning_rate = 1e-2 # reasonable 1e-4 and 0.1\n",
        "\n",
        "kf = KFold(n_splits=num_folds, shuffle=True)\n",
        "\n",
        "all_true_labels = []\n",
        "all_pred_labels = []\n",
        "all_fold_acc_history = []\n",
        "start_time = time.time()\n",
        "\n",
        "for fold, (train_indices, val_indices) in enumerate(kf.split(test_data)):\n",
        "    model = Model2()\n",
        "    criterion = nn.BCELoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), weight_decay=weight_decay)\n",
        "\n",
        "    train_fold_data = torch.utils.data.Subset(train_data, train_indices)\n",
        "    val_fold_data = torch.utils.data.Subset(test_data, val_indices)\n",
        "    train_fold_loader = torch.utils.data.DataLoader(train_fold_data, batch_size=32, shuffle=True)\n",
        "    val_fold_loader = torch.utils.data.DataLoader(val_fold_data, batch_size=32, shuffle=False)\n",
        "\n",
        "    fold_acc_history = []\n",
        "    for epoch in range(num_epochs):\n",
        "        train_loss = 0\n",
        "        train_acc = 0\n",
        "        for inputs, labels in train_fold_loader:\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            #ipdb.set_trace()\n",
        "            loss = criterion(outputs, encode_labels(labels))\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            train_loss += loss.item()\n",
        "        train_loss /= len(val_fold_loader)\n",
        "        print(f\"Validation fold {fold + 1}, epoch {epoch + 1}: train_loss = {train_loss:.2f}\")\n",
        "\n",
        "        with torch.no_grad():\n",
        "            model.eval()\n",
        "            val_loss = 0\n",
        "            val_acc = 0\n",
        "            true_labels = []\n",
        "            pred_labels = []\n",
        "            for inputs, labels in val_fold_loader:\n",
        "                outputs = model(inputs)\n",
        "                loss = criterion(outputs, encode_labels(labels))\n",
        "                val_loss += loss.item()\n",
        "                y_pred = np.argmax(outputs, axis=1)\n",
        "                true_labels += labels.tolist()\n",
        "                pred_labels += y_pred.round().tolist()\n",
        "            val_loss /= len(val_fold_loader)\n",
        "\n",
        "        val_acc = accuracy_score(true_labels, pred_labels)\n",
        "        fold_acc_history.append(val_acc)\n",
        "        print(f\"Fold {fold + 1}: val_loss = {val_loss:.2f}, val_acc = {val_acc:.2f}\")\n",
        "    all_fold_acc_history.append(fold_acc_history)\n",
        "    all_true_labels += true_labels\n",
        "    all_pred_labels += pred_labels\n",
        "\n",
        "# Compute the overall confusion matrix and accuracy\n",
        "overall_cm = confusion_matrix(all_true_labels, all_pred_labels)\n",
        "overall_acc = accuracy_score(all_true_labels, all_pred_labels)\n",
        "\n",
        "# Print the overall confusion matrix and accuracy\n",
        "print(f\"Overall confusion matrix:\\n{overall_cm}\")\n",
        "print(f\"Overall accuracy: {overall_acc:.2f}\")\n",
        "\n",
        "# Compute the average accuracy over all folds for each epoch\n",
        "mean_acc_history = [sum([fold_acc_history[i] for fold_acc_history in all_fold_acc_history])/num_folds for i in range(len(all_fold_acc_history[0]))]\n",
        "\n",
        "# Plot the average accuracy over all folds over time\n",
        "plt.plot(mean_acc_history)\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Average Accuracy over Time')\n",
        "plt.show()\n",
        "end_time = time.time()\n",
        "execution_time = end_time - start_time\n",
        "print(f\"Execution time of: {execution_time} seconds\")\n",
        "\n",
        "from datetime import datetime\n",
        "timestamp = str(int(time.time()))  # Obtain the current timestamp\n",
        "torch.save(model.state_dict(), '/content/drive/MyDrive/Ghost Lab/cog 2023/camera-ready/Zelda-data/passive/model_'+timestamp+'_.h5')\n",
        "\n",
        "json_object = json.dumps({\n",
        "    'folds' : num_folds, 'epochs' : num_epochs,\n",
        "    'weight_decay' : weight_decay, 'learning_rate': learning_rate,\n",
        "    'execution_time' : execution_time}, indent=4)\n",
        "with open('/content/drive/MyDrive/Ghost Lab/cog 2023/camera-ready/Zelda-data/passive/parameters-'+timestamp+'.json', 'w') as outfile:\n",
        "    outfile.write(json_object)\n",
        "\n",
        "with open('/content/drive/MyDrive/Ghost Lab/cog 2023/camera-ready/Zelda-data/passive/parameters-'+timestamp+'.pickle', 'wb') as handle:\n",
        "    pickle.dump(\n",
        "        {'all_fold_acc_history' : all_fold_acc_history,'confusion' : overall_cm}\n",
        "        , handle)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "50_j9lB7KOvP",
        "outputId": "3993f5b8-660a-4df6-c7a9-a4da285a6551"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "410\n",
            "1638\n",
            "Validation fold 1, epoch 1: train_loss = 2.55\n",
            "Fold 1: val_loss = 0.69, val_acc = 0.59\n",
            "Validation fold 1, epoch 2: train_loss = 2.54\n",
            "Fold 1: val_loss = 0.69, val_acc = 0.59\n",
            "Validation fold 1, epoch 3: train_loss = 2.54\n",
            "Fold 1: val_loss = 0.69, val_acc = 0.59\n",
            "Validation fold 1, epoch 4: train_loss = 2.53\n",
            "Fold 1: val_loss = 0.69, val_acc = 0.59\n",
            "Validation fold 1, epoch 5: train_loss = 2.49\n",
            "Fold 1: val_loss = 0.69, val_acc = 0.59\n",
            "Validation fold 1, epoch 6: train_loss = 2.42\n",
            "Fold 1: val_loss = 0.71, val_acc = 0.41\n",
            "Validation fold 1, epoch 7: train_loss = 2.02\n",
            "Fold 1: val_loss = 0.93, val_acc = 0.50\n",
            "Validation fold 1, epoch 8: train_loss = 1.56\n",
            "Fold 1: val_loss = 1.28, val_acc = 0.41\n",
            "Validation fold 1, epoch 9: train_loss = 1.20\n",
            "Fold 1: val_loss = 1.28, val_acc = 0.41\n",
            "Validation fold 1, epoch 10: train_loss = 1.13\n",
            "Fold 1: val_loss = 1.29, val_acc = 0.40\n",
            "Validation fold 1, epoch 11: train_loss = 0.92\n",
            "Fold 1: val_loss = 1.39, val_acc = 0.45\n",
            "Validation fold 1, epoch 12: train_loss = 0.61\n",
            "Fold 1: val_loss = 1.57, val_acc = 0.43\n",
            "Validation fold 1, epoch 13: train_loss = 0.44\n",
            "Fold 1: val_loss = 1.99, val_acc = 0.43\n",
            "Validation fold 1, epoch 14: train_loss = 0.40\n",
            "Fold 1: val_loss = 2.15, val_acc = 0.44\n",
            "Validation fold 1, epoch 15: train_loss = 0.30\n",
            "Fold 1: val_loss = 2.30, val_acc = 0.44\n",
            "Validation fold 1, epoch 16: train_loss = 0.35\n",
            "Fold 1: val_loss = 2.33, val_acc = 0.41\n",
            "Validation fold 1, epoch 17: train_loss = 0.25\n",
            "Fold 1: val_loss = 2.16, val_acc = 0.43\n",
            "Validation fold 1, epoch 18: train_loss = 0.23\n",
            "Fold 1: val_loss = 2.15, val_acc = 0.40\n",
            "Validation fold 1, epoch 19: train_loss = 0.30\n",
            "Fold 1: val_loss = 2.72, val_acc = 0.43\n",
            "Validation fold 1, epoch 20: train_loss = 0.50\n",
            "Fold 1: val_loss = 2.38, val_acc = 0.41\n",
            "Validation fold 1, epoch 21: train_loss = 0.53\n",
            "Fold 1: val_loss = 1.91, val_acc = 0.41\n",
            "Validation fold 1, epoch 22: train_loss = 0.38\n",
            "Fold 1: val_loss = 2.50, val_acc = 0.41\n",
            "Validation fold 1, epoch 23: train_loss = 0.37\n",
            "Fold 1: val_loss = 2.22, val_acc = 0.43\n",
            "Validation fold 1, epoch 24: train_loss = 0.28\n",
            "Fold 1: val_loss = 2.23, val_acc = 0.40\n",
            "Validation fold 1, epoch 25: train_loss = 0.12\n",
            "Fold 1: val_loss = 2.45, val_acc = 0.41\n",
            "Validation fold 1, epoch 26: train_loss = 0.17\n",
            "Fold 1: val_loss = 2.76, val_acc = 0.43\n",
            "Validation fold 1, epoch 27: train_loss = 0.09\n",
            "Fold 1: val_loss = 2.94, val_acc = 0.41\n",
            "Validation fold 1, epoch 28: train_loss = 0.07\n",
            "Fold 1: val_loss = 3.12, val_acc = 0.41\n",
            "Validation fold 1, epoch 29: train_loss = 0.09\n",
            "Fold 1: val_loss = 3.08, val_acc = 0.41\n",
            "Validation fold 1, epoch 30: train_loss = 0.18\n",
            "Fold 1: val_loss = 2.94, val_acc = 0.43\n",
            "Validation fold 1, epoch 31: train_loss = 0.22\n",
            "Fold 1: val_loss = 3.13, val_acc = 0.43\n",
            "Validation fold 1, epoch 32: train_loss = 0.50\n",
            "Fold 1: val_loss = 2.34, val_acc = 0.41\n",
            "Validation fold 1, epoch 33: train_loss = 0.58\n",
            "Fold 1: val_loss = 1.93, val_acc = 0.44\n",
            "Validation fold 1, epoch 34: train_loss = 0.37\n",
            "Fold 1: val_loss = 2.27, val_acc = 0.41\n",
            "Validation fold 1, epoch 35: train_loss = 0.29\n",
            "Fold 1: val_loss = 2.08, val_acc = 0.40\n",
            "Validation fold 1, epoch 36: train_loss = 0.16\n",
            "Fold 1: val_loss = 2.50, val_acc = 0.41\n",
            "Validation fold 1, epoch 37: train_loss = 0.11\n",
            "Fold 1: val_loss = 2.57, val_acc = 0.39\n",
            "Validation fold 1, epoch 38: train_loss = 0.10\n",
            "Fold 1: val_loss = 3.03, val_acc = 0.41\n",
            "Validation fold 1, epoch 39: train_loss = 0.04\n",
            "Fold 1: val_loss = 3.15, val_acc = 0.40\n",
            "Validation fold 1, epoch 40: train_loss = 0.03\n",
            "Fold 1: val_loss = 3.27, val_acc = 0.39\n",
            "Validation fold 1, epoch 41: train_loss = 0.03\n",
            "Fold 1: val_loss = 3.26, val_acc = 0.39\n",
            "Validation fold 1, epoch 42: train_loss = 0.03\n",
            "Fold 1: val_loss = 3.52, val_acc = 0.43\n",
            "Validation fold 1, epoch 43: train_loss = 0.03\n",
            "Fold 1: val_loss = 3.40, val_acc = 0.39\n",
            "Validation fold 1, epoch 44: train_loss = 0.02\n",
            "Fold 1: val_loss = 3.46, val_acc = 0.39\n",
            "Validation fold 1, epoch 45: train_loss = 0.02\n",
            "Fold 1: val_loss = 3.45, val_acc = 0.39\n",
            "Validation fold 1, epoch 46: train_loss = 0.01\n",
            "Fold 1: val_loss = 3.54, val_acc = 0.40\n",
            "Validation fold 1, epoch 47: train_loss = 0.01\n",
            "Fold 1: val_loss = 3.52, val_acc = 0.40\n",
            "Validation fold 1, epoch 48: train_loss = 0.01\n",
            "Fold 1: val_loss = 3.48, val_acc = 0.39\n",
            "Validation fold 1, epoch 49: train_loss = 0.01\n",
            "Fold 1: val_loss = 3.52, val_acc = 0.40\n",
            "Validation fold 1, epoch 50: train_loss = 0.01\n",
            "Fold 1: val_loss = 3.54, val_acc = 0.40\n",
            "Validation fold 2, epoch 1: train_loss = 2.55\n",
            "Fold 2: val_loss = 0.69, val_acc = 0.55\n",
            "Validation fold 2, epoch 2: train_loss = 2.54\n",
            "Fold 2: val_loss = 0.69, val_acc = 0.55\n",
            "Validation fold 2, epoch 3: train_loss = 2.52\n",
            "Fold 2: val_loss = 0.69, val_acc = 0.51\n",
            "Validation fold 2, epoch 4: train_loss = 2.47\n",
            "Fold 2: val_loss = 0.71, val_acc = 0.48\n",
            "Validation fold 2, epoch 5: train_loss = 2.36\n",
            "Fold 2: val_loss = 0.71, val_acc = 0.51\n",
            "Validation fold 2, epoch 6: train_loss = 1.81\n",
            "Fold 2: val_loss = 1.02, val_acc = 0.51\n",
            "Validation fold 2, epoch 7: train_loss = 1.93\n",
            "Fold 2: val_loss = 0.89, val_acc = 0.56\n",
            "Validation fold 2, epoch 8: train_loss = 1.45\n",
            "Fold 2: val_loss = 0.80, val_acc = 0.57\n",
            "Validation fold 2, epoch 9: train_loss = 1.22\n",
            "Fold 2: val_loss = 1.03, val_acc = 0.59\n",
            "Validation fold 2, epoch 10: train_loss = 1.00\n",
            "Fold 2: val_loss = 1.28, val_acc = 0.57\n",
            "Validation fold 2, epoch 11: train_loss = 0.74\n",
            "Fold 2: val_loss = 1.53, val_acc = 0.59\n",
            "Validation fold 2, epoch 12: train_loss = 0.86\n",
            "Fold 2: val_loss = 1.39, val_acc = 0.55\n",
            "Validation fold 2, epoch 13: train_loss = 0.74\n",
            "Fold 2: val_loss = 1.37, val_acc = 0.56\n",
            "Validation fold 2, epoch 14: train_loss = 0.46\n",
            "Fold 2: val_loss = 1.57, val_acc = 0.54\n",
            "Validation fold 2, epoch 15: train_loss = 0.35\n",
            "Fold 2: val_loss = 1.84, val_acc = 0.52\n",
            "Validation fold 2, epoch 16: train_loss = 0.43\n",
            "Fold 2: val_loss = 1.86, val_acc = 0.54\n",
            "Validation fold 2, epoch 17: train_loss = 0.30\n",
            "Fold 2: val_loss = 1.75, val_acc = 0.52\n",
            "Validation fold 2, epoch 18: train_loss = 0.25\n",
            "Fold 2: val_loss = 1.91, val_acc = 0.51\n",
            "Validation fold 2, epoch 19: train_loss = 0.14\n",
            "Fold 2: val_loss = 2.24, val_acc = 0.54\n",
            "Validation fold 2, epoch 20: train_loss = 0.15\n",
            "Fold 2: val_loss = 2.39, val_acc = 0.54\n",
            "Validation fold 2, epoch 21: train_loss = 0.15\n",
            "Fold 2: val_loss = 2.52, val_acc = 0.57\n",
            "Validation fold 2, epoch 22: train_loss = 0.42\n",
            "Fold 2: val_loss = 2.28, val_acc = 0.51\n",
            "Validation fold 2, epoch 23: train_loss = 0.24\n",
            "Fold 2: val_loss = 2.16, val_acc = 0.56\n",
            "Validation fold 2, epoch 24: train_loss = 0.22\n",
            "Fold 2: val_loss = 2.05, val_acc = 0.54\n",
            "Validation fold 2, epoch 25: train_loss = 0.19\n",
            "Fold 2: val_loss = 2.31, val_acc = 0.56\n",
            "Validation fold 2, epoch 26: train_loss = 0.19\n",
            "Fold 2: val_loss = 2.51, val_acc = 0.54\n",
            "Validation fold 2, epoch 27: train_loss = 0.39\n",
            "Fold 2: val_loss = 2.40, val_acc = 0.54\n",
            "Validation fold 2, epoch 28: train_loss = 0.26\n",
            "Fold 2: val_loss = 2.22, val_acc = 0.55\n",
            "Validation fold 2, epoch 29: train_loss = 0.33\n",
            "Fold 2: val_loss = 2.04, val_acc = 0.52\n",
            "Validation fold 2, epoch 30: train_loss = 0.21\n",
            "Fold 2: val_loss = 2.28, val_acc = 0.51\n",
            "Validation fold 2, epoch 31: train_loss = 0.25\n",
            "Fold 2: val_loss = 2.39, val_acc = 0.49\n",
            "Validation fold 2, epoch 32: train_loss = 0.18\n",
            "Fold 2: val_loss = 2.40, val_acc = 0.51\n",
            "Validation fold 2, epoch 33: train_loss = 0.13\n",
            "Fold 2: val_loss = 2.48, val_acc = 0.52\n",
            "Validation fold 2, epoch 34: train_loss = 0.05\n",
            "Fold 2: val_loss = 2.59, val_acc = 0.54\n",
            "Validation fold 2, epoch 35: train_loss = 0.03\n",
            "Fold 2: val_loss = 2.79, val_acc = 0.56\n",
            "Validation fold 2, epoch 36: train_loss = 0.02\n",
            "Fold 2: val_loss = 2.83, val_acc = 0.54\n",
            "Validation fold 2, epoch 37: train_loss = 0.02\n",
            "Fold 2: val_loss = 2.87, val_acc = 0.54\n",
            "Validation fold 2, epoch 38: train_loss = 0.02\n",
            "Fold 2: val_loss = 2.97, val_acc = 0.54\n",
            "Validation fold 2, epoch 39: train_loss = 0.02\n",
            "Fold 2: val_loss = 2.91, val_acc = 0.54\n",
            "Validation fold 2, epoch 40: train_loss = 0.06\n",
            "Fold 2: val_loss = 3.01, val_acc = 0.54\n",
            "Validation fold 2, epoch 41: train_loss = 0.09\n",
            "Fold 2: val_loss = 3.03, val_acc = 0.54\n",
            "Validation fold 2, epoch 42: train_loss = 0.21\n",
            "Fold 2: val_loss = 2.70, val_acc = 0.59\n",
            "Validation fold 2, epoch 43: train_loss = 0.41\n",
            "Fold 2: val_loss = 2.01, val_acc = 0.59\n",
            "Validation fold 2, epoch 44: train_loss = 0.54\n",
            "Fold 2: val_loss = 1.64, val_acc = 0.59\n",
            "Validation fold 2, epoch 45: train_loss = 0.40\n",
            "Fold 2: val_loss = 1.65, val_acc = 0.57\n",
            "Validation fold 2, epoch 46: train_loss = 0.22\n",
            "Fold 2: val_loss = 2.03, val_acc = 0.55\n",
            "Validation fold 2, epoch 47: train_loss = 0.10\n",
            "Fold 2: val_loss = 2.48, val_acc = 0.55\n",
            "Validation fold 2, epoch 48: train_loss = 0.06\n",
            "Fold 2: val_loss = 2.65, val_acc = 0.52\n",
            "Validation fold 2, epoch 49: train_loss = 0.02\n",
            "Fold 2: val_loss = 2.87, val_acc = 0.52\n",
            "Validation fold 2, epoch 50: train_loss = 0.01\n",
            "Fold 2: val_loss = 2.95, val_acc = 0.54\n",
            "Validation fold 3, epoch 1: train_loss = 2.54\n",
            "Fold 3: val_loss = 0.71, val_acc = 0.49\n",
            "Validation fold 3, epoch 2: train_loss = 2.53\n",
            "Fold 3: val_loss = 0.70, val_acc = 0.49\n",
            "Validation fold 3, epoch 3: train_loss = 2.51\n",
            "Fold 3: val_loss = 0.70, val_acc = 0.49\n",
            "Validation fold 3, epoch 4: train_loss = 2.54\n",
            "Fold 3: val_loss = 0.69, val_acc = 0.49\n",
            "Validation fold 3, epoch 5: train_loss = 2.48\n",
            "Fold 3: val_loss = 0.74, val_acc = 0.49\n",
            "Validation fold 3, epoch 6: train_loss = 2.46\n",
            "Fold 3: val_loss = 0.70, val_acc = 0.50\n",
            "Validation fold 3, epoch 7: train_loss = 2.36\n",
            "Fold 3: val_loss = 0.76, val_acc = 0.35\n",
            "Validation fold 3, epoch 8: train_loss = 2.12\n",
            "Fold 3: val_loss = 0.99, val_acc = 0.35\n",
            "Validation fold 3, epoch 9: train_loss = 1.56\n",
            "Fold 3: val_loss = 1.88, val_acc = 0.40\n",
            "Validation fold 3, epoch 10: train_loss = 1.46\n",
            "Fold 3: val_loss = 1.24, val_acc = 0.39\n",
            "Validation fold 3, epoch 11: train_loss = 1.25\n",
            "Fold 3: val_loss = 1.29, val_acc = 0.37\n",
            "Validation fold 3, epoch 12: train_loss = 1.22\n",
            "Fold 3: val_loss = 1.37, val_acc = 0.37\n",
            "Validation fold 3, epoch 13: train_loss = 1.23\n",
            "Fold 3: val_loss = 1.66, val_acc = 0.35\n",
            "Validation fold 3, epoch 14: train_loss = 1.30\n",
            "Fold 3: val_loss = 1.75, val_acc = 0.37\n",
            "Validation fold 3, epoch 15: train_loss = 0.95\n",
            "Fold 3: val_loss = 1.78, val_acc = 0.38\n",
            "Validation fold 3, epoch 16: train_loss = 0.68\n",
            "Fold 3: val_loss = 2.61, val_acc = 0.40\n",
            "Validation fold 3, epoch 17: train_loss = 0.57\n",
            "Fold 3: val_loss = 3.12, val_acc = 0.39\n",
            "Validation fold 3, epoch 18: train_loss = 0.64\n",
            "Fold 3: val_loss = 2.96, val_acc = 0.38\n",
            "Validation fold 3, epoch 19: train_loss = 0.96\n",
            "Fold 3: val_loss = 2.10, val_acc = 0.41\n",
            "Validation fold 3, epoch 20: train_loss = 0.88\n",
            "Fold 3: val_loss = 1.71, val_acc = 0.38\n",
            "Validation fold 3, epoch 21: train_loss = 0.48\n",
            "Fold 3: val_loss = 2.39, val_acc = 0.38\n",
            "Validation fold 3, epoch 22: train_loss = 0.38\n",
            "Fold 3: val_loss = 2.94, val_acc = 0.38\n",
            "Validation fold 3, epoch 23: train_loss = 0.33\n",
            "Fold 3: val_loss = 3.04, val_acc = 0.38\n",
            "Validation fold 3, epoch 24: train_loss = 0.28\n",
            "Fold 3: val_loss = 3.38, val_acc = 0.39\n",
            "Validation fold 3, epoch 25: train_loss = 0.25\n",
            "Fold 3: val_loss = 3.51, val_acc = 0.38\n",
            "Validation fold 3, epoch 26: train_loss = 0.33\n",
            "Fold 3: val_loss = 3.54, val_acc = 0.37\n",
            "Validation fold 3, epoch 27: train_loss = 0.34\n",
            "Fold 3: val_loss = 2.88, val_acc = 0.35\n",
            "Validation fold 3, epoch 28: train_loss = 0.20\n",
            "Fold 3: val_loss = 3.09, val_acc = 0.37\n",
            "Validation fold 3, epoch 29: train_loss = 0.27\n",
            "Fold 3: val_loss = 3.15, val_acc = 0.40\n",
            "Validation fold 3, epoch 30: train_loss = 0.32\n",
            "Fold 3: val_loss = 3.34, val_acc = 0.39\n",
            "Validation fold 3, epoch 31: train_loss = 0.26\n",
            "Fold 3: val_loss = 3.47, val_acc = 0.38\n",
            "Validation fold 3, epoch 32: train_loss = 0.43\n",
            "Fold 3: val_loss = 3.10, val_acc = 0.39\n",
            "Validation fold 3, epoch 33: train_loss = 0.34\n",
            "Fold 3: val_loss = 2.51, val_acc = 0.45\n",
            "Validation fold 3, epoch 34: train_loss = 0.28\n",
            "Fold 3: val_loss = 3.14, val_acc = 0.40\n",
            "Validation fold 3, epoch 35: train_loss = 0.17\n",
            "Fold 3: val_loss = 3.84, val_acc = 0.39\n",
            "Validation fold 3, epoch 36: train_loss = 0.17\n",
            "Fold 3: val_loss = 3.41, val_acc = 0.39\n",
            "Validation fold 3, epoch 37: train_loss = 0.08\n",
            "Fold 3: val_loss = 3.71, val_acc = 0.39\n",
            "Validation fold 3, epoch 38: train_loss = 0.07\n",
            "Fold 3: val_loss = 4.12, val_acc = 0.40\n",
            "Validation fold 3, epoch 39: train_loss = 0.05\n",
            "Fold 3: val_loss = 4.03, val_acc = 0.39\n",
            "Validation fold 3, epoch 40: train_loss = 0.04\n",
            "Fold 3: val_loss = 4.52, val_acc = 0.39\n",
            "Validation fold 3, epoch 41: train_loss = 0.08\n",
            "Fold 3: val_loss = 4.16, val_acc = 0.40\n",
            "Validation fold 3, epoch 42: train_loss = 0.04\n",
            "Fold 3: val_loss = 4.25, val_acc = 0.39\n",
            "Validation fold 3, epoch 43: train_loss = 0.02\n",
            "Fold 3: val_loss = 4.23, val_acc = 0.39\n",
            "Validation fold 3, epoch 44: train_loss = 0.02\n",
            "Fold 3: val_loss = 4.30, val_acc = 0.40\n",
            "Validation fold 3, epoch 45: train_loss = 0.02\n",
            "Fold 3: val_loss = 4.40, val_acc = 0.41\n",
            "Validation fold 3, epoch 46: train_loss = 0.04\n",
            "Fold 3: val_loss = 4.51, val_acc = 0.39\n",
            "Validation fold 3, epoch 47: train_loss = 0.02\n",
            "Fold 3: val_loss = 4.40, val_acc = 0.39\n",
            "Validation fold 3, epoch 48: train_loss = 0.02\n",
            "Fold 3: val_loss = 4.64, val_acc = 0.39\n",
            "Validation fold 3, epoch 49: train_loss = 0.04\n",
            "Fold 3: val_loss = 4.43, val_acc = 0.39\n",
            "Validation fold 3, epoch 50: train_loss = 0.05\n",
            "Fold 3: val_loss = 4.37, val_acc = 0.38\n",
            "Validation fold 4, epoch 1: train_loss = 2.54\n",
            "Fold 4: val_loss = 0.69, val_acc = 0.52\n",
            "Validation fold 4, epoch 2: train_loss = 2.54\n",
            "Fold 4: val_loss = 0.69, val_acc = 0.52\n",
            "Validation fold 4, epoch 3: train_loss = 2.54\n",
            "Fold 4: val_loss = 0.69, val_acc = 0.52\n",
            "Validation fold 4, epoch 4: train_loss = 2.53\n",
            "Fold 4: val_loss = 0.69, val_acc = 0.50\n",
            "Validation fold 4, epoch 5: train_loss = 2.43\n",
            "Fold 4: val_loss = 0.72, val_acc = 0.45\n",
            "Validation fold 4, epoch 6: train_loss = 2.07\n",
            "Fold 4: val_loss = 0.95, val_acc = 0.40\n",
            "Validation fold 4, epoch 7: train_loss = 1.58\n",
            "Fold 4: val_loss = 1.40, val_acc = 0.50\n",
            "Validation fold 4, epoch 8: train_loss = 1.87\n",
            "Fold 4: val_loss = 1.13, val_acc = 0.46\n",
            "Validation fold 4, epoch 9: train_loss = 1.46\n",
            "Fold 4: val_loss = 1.06, val_acc = 0.44\n",
            "Validation fold 4, epoch 10: train_loss = 1.12\n",
            "Fold 4: val_loss = 1.32, val_acc = 0.43\n",
            "Validation fold 4, epoch 11: train_loss = 1.00\n",
            "Fold 4: val_loss = 1.61, val_acc = 0.45\n",
            "Validation fold 4, epoch 12: train_loss = 0.81\n",
            "Fold 4: val_loss = 1.77, val_acc = 0.48\n",
            "Validation fold 4, epoch 13: train_loss = 0.71\n",
            "Fold 4: val_loss = 1.66, val_acc = 0.45\n",
            "Validation fold 4, epoch 14: train_loss = 0.54\n",
            "Fold 4: val_loss = 2.00, val_acc = 0.41\n",
            "Validation fold 4, epoch 15: train_loss = 0.53\n",
            "Fold 4: val_loss = 2.32, val_acc = 0.50\n",
            "Validation fold 4, epoch 16: train_loss = 0.36\n",
            "Fold 4: val_loss = 2.27, val_acc = 0.41\n",
            "Validation fold 4, epoch 17: train_loss = 0.38\n",
            "Fold 4: val_loss = 2.26, val_acc = 0.43\n",
            "Validation fold 4, epoch 18: train_loss = 0.32\n",
            "Fold 4: val_loss = 2.31, val_acc = 0.48\n",
            "Validation fold 4, epoch 19: train_loss = 0.30\n",
            "Fold 4: val_loss = 2.33, val_acc = 0.44\n",
            "Validation fold 4, epoch 20: train_loss = 0.25\n",
            "Fold 4: val_loss = 2.42, val_acc = 0.45\n",
            "Validation fold 4, epoch 21: train_loss = 0.14\n",
            "Fold 4: val_loss = 2.56, val_acc = 0.44\n",
            "Validation fold 4, epoch 22: train_loss = 0.10\n",
            "Fold 4: val_loss = 2.74, val_acc = 0.43\n",
            "Validation fold 4, epoch 23: train_loss = 0.10\n",
            "Fold 4: val_loss = 2.85, val_acc = 0.44\n",
            "Validation fold 4, epoch 24: train_loss = 0.11\n",
            "Fold 4: val_loss = 2.93, val_acc = 0.43\n",
            "Validation fold 4, epoch 25: train_loss = 0.06\n",
            "Fold 4: val_loss = 3.03, val_acc = 0.43\n",
            "Validation fold 4, epoch 26: train_loss = 0.04\n",
            "Fold 4: val_loss = 3.16, val_acc = 0.44\n",
            "Validation fold 4, epoch 27: train_loss = 0.04\n",
            "Fold 4: val_loss = 3.25, val_acc = 0.44\n",
            "Validation fold 4, epoch 28: train_loss = 0.04\n",
            "Fold 4: val_loss = 3.39, val_acc = 0.48\n",
            "Validation fold 4, epoch 29: train_loss = 0.20\n",
            "Fold 4: val_loss = 3.29, val_acc = 0.43\n",
            "Validation fold 4, epoch 30: train_loss = 0.29\n",
            "Fold 4: val_loss = 3.08, val_acc = 0.40\n",
            "Validation fold 4, epoch 31: train_loss = 0.70\n",
            "Fold 4: val_loss = 2.16, val_acc = 0.44\n",
            "Validation fold 4, epoch 32: train_loss = 0.36\n",
            "Fold 4: val_loss = 2.05, val_acc = 0.46\n",
            "Validation fold 4, epoch 33: train_loss = 0.27\n",
            "Fold 4: val_loss = 2.23, val_acc = 0.48\n",
            "Validation fold 4, epoch 34: train_loss = 0.15\n",
            "Fold 4: val_loss = 2.53, val_acc = 0.48\n",
            "Validation fold 4, epoch 35: train_loss = 0.08\n",
            "Fold 4: val_loss = 2.86, val_acc = 0.45\n",
            "Validation fold 4, epoch 36: train_loss = 0.04\n",
            "Fold 4: val_loss = 3.08, val_acc = 0.41\n",
            "Validation fold 4, epoch 37: train_loss = 0.07\n",
            "Fold 4: val_loss = 3.28, val_acc = 0.40\n",
            "Validation fold 4, epoch 38: train_loss = 0.25\n",
            "Fold 4: val_loss = 3.15, val_acc = 0.41\n",
            "Validation fold 4, epoch 39: train_loss = 0.16\n",
            "Fold 4: val_loss = 2.79, val_acc = 0.43\n",
            "Validation fold 4, epoch 40: train_loss = 0.17\n",
            "Fold 4: val_loss = 2.71, val_acc = 0.40\n",
            "Validation fold 4, epoch 41: train_loss = 0.15\n",
            "Fold 4: val_loss = 2.68, val_acc = 0.40\n",
            "Validation fold 4, epoch 42: train_loss = 0.12\n",
            "Fold 4: val_loss = 2.76, val_acc = 0.52\n",
            "Validation fold 4, epoch 43: train_loss = 0.09\n",
            "Fold 4: val_loss = 2.77, val_acc = 0.43\n",
            "Validation fold 4, epoch 44: train_loss = 0.06\n",
            "Fold 4: val_loss = 2.75, val_acc = 0.41\n",
            "Validation fold 4, epoch 45: train_loss = 0.04\n",
            "Fold 4: val_loss = 2.90, val_acc = 0.41\n",
            "Validation fold 4, epoch 46: train_loss = 0.03\n",
            "Fold 4: val_loss = 3.08, val_acc = 0.49\n",
            "Validation fold 4, epoch 47: train_loss = 0.03\n",
            "Fold 4: val_loss = 3.15, val_acc = 0.38\n",
            "Validation fold 4, epoch 48: train_loss = 0.02\n",
            "Fold 4: val_loss = 3.18, val_acc = 0.48\n",
            "Validation fold 4, epoch 49: train_loss = 0.01\n",
            "Fold 4: val_loss = 3.20, val_acc = 0.41\n",
            "Validation fold 4, epoch 50: train_loss = 0.01\n",
            "Fold 4: val_loss = 3.22, val_acc = 0.41\n",
            "Validation fold 5, epoch 1: train_loss = 2.54\n",
            "Fold 5: val_loss = 0.69, val_acc = 0.61\n",
            "Validation fold 5, epoch 2: train_loss = 2.54\n",
            "Fold 5: val_loss = 0.69, val_acc = 0.49\n",
            "Validation fold 5, epoch 3: train_loss = 2.52\n",
            "Fold 5: val_loss = 0.69, val_acc = 0.59\n",
            "Validation fold 5, epoch 4: train_loss = 2.34\n",
            "Fold 5: val_loss = 0.69, val_acc = 0.54\n",
            "Validation fold 5, epoch 5: train_loss = 2.17\n",
            "Fold 5: val_loss = 0.85, val_acc = 0.56\n",
            "Validation fold 5, epoch 6: train_loss = 1.70\n",
            "Fold 5: val_loss = 0.90, val_acc = 0.50\n",
            "Validation fold 5, epoch 7: train_loss = 1.42\n",
            "Fold 5: val_loss = 1.12, val_acc = 0.50\n",
            "Validation fold 5, epoch 8: train_loss = 1.08\n",
            "Fold 5: val_loss = 1.50, val_acc = 0.48\n",
            "Validation fold 5, epoch 9: train_loss = 1.10\n",
            "Fold 5: val_loss = 1.45, val_acc = 0.54\n",
            "Validation fold 5, epoch 10: train_loss = 0.99\n",
            "Fold 5: val_loss = 1.26, val_acc = 0.55\n",
            "Validation fold 5, epoch 11: train_loss = 0.85\n",
            "Fold 5: val_loss = 1.41, val_acc = 0.48\n",
            "Validation fold 5, epoch 12: train_loss = 0.69\n",
            "Fold 5: val_loss = 2.00, val_acc = 0.48\n",
            "Validation fold 5, epoch 13: train_loss = 0.68\n",
            "Fold 5: val_loss = 1.83, val_acc = 0.44\n",
            "Validation fold 5, epoch 14: train_loss = 0.52\n",
            "Fold 5: val_loss = 1.75, val_acc = 0.52\n",
            "Validation fold 5, epoch 15: train_loss = 0.38\n",
            "Fold 5: val_loss = 2.00, val_acc = 0.52\n",
            "Validation fold 5, epoch 16: train_loss = 0.60\n",
            "Fold 5: val_loss = 2.07, val_acc = 0.52\n",
            "Validation fold 5, epoch 17: train_loss = 0.29\n",
            "Fold 5: val_loss = 2.20, val_acc = 0.46\n",
            "Validation fold 5, epoch 18: train_loss = 0.18\n",
            "Fold 5: val_loss = 2.43, val_acc = 0.48\n",
            "Validation fold 5, epoch 19: train_loss = 0.16\n",
            "Fold 5: val_loss = 2.63, val_acc = 0.48\n",
            "Validation fold 5, epoch 20: train_loss = 0.17\n",
            "Fold 5: val_loss = 2.59, val_acc = 0.51\n",
            "Validation fold 5, epoch 21: train_loss = 0.19\n",
            "Fold 5: val_loss = 2.55, val_acc = 0.51\n",
            "Validation fold 5, epoch 22: train_loss = 0.20\n",
            "Fold 5: val_loss = 2.93, val_acc = 0.41\n",
            "Validation fold 5, epoch 23: train_loss = 0.37\n",
            "Fold 5: val_loss = 2.72, val_acc = 0.44\n",
            "Validation fold 5, epoch 24: train_loss = 0.34\n",
            "Fold 5: val_loss = 2.54, val_acc = 0.46\n",
            "Validation fold 5, epoch 25: train_loss = 0.13\n",
            "Fold 5: val_loss = 2.31, val_acc = 0.46\n",
            "Validation fold 5, epoch 26: train_loss = 0.09\n",
            "Fold 5: val_loss = 2.44, val_acc = 0.50\n",
            "Validation fold 5, epoch 27: train_loss = 0.06\n",
            "Fold 5: val_loss = 2.70, val_acc = 0.52\n",
            "Validation fold 5, epoch 28: train_loss = 0.03\n",
            "Fold 5: val_loss = 2.96, val_acc = 0.51\n",
            "Validation fold 5, epoch 29: train_loss = 0.02\n",
            "Fold 5: val_loss = 3.21, val_acc = 0.46\n",
            "Validation fold 5, epoch 30: train_loss = 0.02\n",
            "Fold 5: val_loss = 3.27, val_acc = 0.52\n",
            "Validation fold 5, epoch 31: train_loss = 0.03\n",
            "Fold 5: val_loss = 3.56, val_acc = 0.46\n",
            "Validation fold 5, epoch 32: train_loss = 0.04\n",
            "Fold 5: val_loss = 4.08, val_acc = 0.46\n",
            "Validation fold 5, epoch 33: train_loss = 0.01\n",
            "Fold 5: val_loss = 3.55, val_acc = 0.52\n",
            "Validation fold 5, epoch 34: train_loss = 0.01\n",
            "Fold 5: val_loss = 4.00, val_acc = 0.54\n",
            "Validation fold 5, epoch 35: train_loss = 0.01\n",
            "Fold 5: val_loss = 4.14, val_acc = 0.46\n",
            "Validation fold 5, epoch 36: train_loss = 0.01\n",
            "Fold 5: val_loss = 4.06, val_acc = 0.51\n",
            "Validation fold 5, epoch 37: train_loss = 0.01\n",
            "Fold 5: val_loss = 4.13, val_acc = 0.49\n",
            "Validation fold 5, epoch 38: train_loss = 0.01\n",
            "Fold 5: val_loss = 4.03, val_acc = 0.52\n",
            "Validation fold 5, epoch 39: train_loss = 0.01\n",
            "Fold 5: val_loss = 4.21, val_acc = 0.46\n",
            "Validation fold 5, epoch 40: train_loss = 0.01\n",
            "Fold 5: val_loss = 4.12, val_acc = 0.50\n",
            "Validation fold 5, epoch 41: train_loss = 0.01\n",
            "Fold 5: val_loss = 4.13, val_acc = 0.50\n",
            "Validation fold 5, epoch 42: train_loss = 0.01\n",
            "Fold 5: val_loss = 4.22, val_acc = 0.48\n",
            "Validation fold 5, epoch 43: train_loss = 0.01\n",
            "Fold 5: val_loss = 4.18, val_acc = 0.50\n",
            "Validation fold 5, epoch 44: train_loss = 0.01\n",
            "Fold 5: val_loss = 4.21, val_acc = 0.48\n",
            "Validation fold 5, epoch 45: train_loss = 0.01\n",
            "Fold 5: val_loss = 4.20, val_acc = 0.48\n",
            "Validation fold 5, epoch 46: train_loss = 0.01\n",
            "Fold 5: val_loss = 4.22, val_acc = 0.48\n",
            "Validation fold 5, epoch 47: train_loss = 0.01\n",
            "Fold 5: val_loss = 4.21, val_acc = 0.48\n",
            "Validation fold 5, epoch 48: train_loss = 0.01\n",
            "Fold 5: val_loss = 4.17, val_acc = 0.51\n",
            "Validation fold 5, epoch 49: train_loss = 0.01\n",
            "Fold 5: val_loss = 4.22, val_acc = 0.48\n",
            "Validation fold 5, epoch 50: train_loss = 0.01\n",
            "Fold 5: val_loss = 4.25, val_acc = 0.49\n",
            "Overall confusion matrix:\n",
            "[[ 94 108]\n",
            " [120  88]]\n",
            "Overall accuracy: 0.44\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Execution time of: 23.945706844329834 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Active Learner"
      ],
      "metadata": {
        "id": "snGW9W1BJlQw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import pdb\n",
        "import math\n",
        "import time\n",
        "from datetime import datetime\n",
        "\n",
        "#random_query_strategy\n",
        "#margin_sampling\n",
        "#entropy_sampling\n",
        "#uncertainty_sampling\n",
        "\n",
        "def random_query_strategy(classifier, X, n_instances=1):\n",
        "    indices = list(range(len(X)))\n",
        "    random.shuffle(indices)\n",
        "    return indices[:n_instances]\n",
        "\n",
        "#random_query_strategy\n",
        "#margin_sampling\n",
        "#entropy_sampling\n",
        "#uncertainty_sampling\n",
        "\n",
        "def train_active_learner(strategy, n_queries, n_instances, max_epochs, fraction):\n",
        "    num_folds = 5\n",
        "    num_rounds = 5\n",
        "    all_fold_acc_history = []\n",
        "    all_fold_false_positives = []\n",
        "    all_fold_false_negatives = []\n",
        "    # initial training dataset\n",
        "    X_tensor = torch.FloatTensor(levels)\n",
        "    y_tensor = torch.LongTensor(labels)\n",
        "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "    dataset = torch.utils.data.TensorDataset(torch.tensor(X_tensor).to(device), torch.tensor(y_tensor).to(device))\n",
        "    dataset_loader = torch.utils.data.DataLoader(dataset, batch_size=len(dataset))\n",
        "    X , y = next(iter(dataset_loader))\n",
        "    X = X.detach().cpu().numpy()\n",
        "    y = y.detach().cpu().numpy()\n",
        "    #\n",
        "    X_ini = torch.FloatTensor(initial_x)\n",
        "    y_ini = torch.LongTensor(initial_y)\n",
        "    ini_dataset = torch.utils.data.TensorDataset(torch.tensor(X_ini).to(device), torch.tensor(y_ini).to(device))\n",
        "    ini_loader = torch.utils.data.DataLoader(ini_dataset, batch_size=len(ini_dataset))\n",
        "    X_0 , y_0 = next(iter(ini_loader))\n",
        "    X_0 = X_0.detach().cpu().numpy()\n",
        "    y_0 = y_0.detach().cpu().numpy()\n",
        "\n",
        "    kf = KFold(n_splits=num_folds, shuffle=True)\n",
        "\n",
        "    start_time = time.time()\n",
        "    for fold, (train_indices, val_indices) in enumerate(kf.split(dataset)):\n",
        "        X_train = X[train_indices]\n",
        "        X_test= X[val_indices]\n",
        "        y_train = y[train_indices]\n",
        "        y_test = y[val_indices]\n",
        "\n",
        "        print(f\"Fold no {fold+1}\")\n",
        "        # 5 trials\n",
        "        rounds_accuracies = []\n",
        "        rounds_fps = []\n",
        "        rounds_fns = []\n",
        "        for round in range (0,num_rounds):\n",
        "            print(f\"Fold no {fold+1} . Round no {round+1}\")\n",
        "            this_round_accuracies = []\n",
        "            this_round_fps = 0\n",
        "            this_round_fns = 0\n",
        "            classifier = NeuralNetClassifier(Model, criterion=nn.CrossEntropyLoss,\n",
        "                                 optimizer=torch.optim.Adam, optimizer__weight_decay=0.001,\n",
        "                                 max_epochs = max_epochs, train_split=None,\n",
        "                                 verbose=0, device=device, warm_start = True,)\n",
        "            learner = ActiveLearner(estimator=classifier,X_training=X_0, y_training=y_0,query_strategy=strategy)\n",
        "            y_pred = learner.predict(X_test)\n",
        "            ini_acc = accuracy_score(y_test, y_pred)\n",
        "            print(ini_acc)\n",
        "            fold_acc_history = []\n",
        "            for idx in range(n_queries):\n",
        "                random_indices = np.random.choice(range(len(X_train)), size=math.floor(fraction*len(X_train)), replace=False)\n",
        "                query_idx, query_instance = learner.query(X_train[random_indices], n_instances=n_instances)\n",
        "                x_query = X_train[query_idx]\n",
        "                y_query = y_train[query_idx]\n",
        "                learner.teach(X=x_query, y=y_query)\n",
        "                y_pred = learner.predict(X_test)\n",
        "\n",
        "                true_labels = y_test.tolist()\n",
        "                pred_labels = y_pred.tolist()\n",
        "                for kk in range(len(true_labels)):\n",
        "                    if (pred_labels[kk] == 1) & (true_labels[kk] == 0):\n",
        "                        this_round_fps += 1\n",
        "                    if (pred_labels[kk] == 0) & (true_labels[kk] == 1):\n",
        "                        this_round_fns += 1\n",
        "\n",
        "                val_acc = accuracy_score(y_test, y_pred)\n",
        "                this_round_accuracies.append(val_acc)\n",
        "\n",
        "                X_train = np.delete(X_train, query_idx, axis=0)\n",
        "                y_train = np.delete(y_train, query_idx, axis=0)\n",
        "                print(f\"Fold no {fold+1} . Round no {round+1} . Query no {idx+1}: Acc = {val_acc:.2f}\")\n",
        "            rounds_accuracies.append(this_round_accuracies)\n",
        "            rounds_fps.append(this_round_fps)\n",
        "            rounds_fns.append(this_round_fns)\n",
        "        all_rounds_mean_accuracy = np.mean(rounds_accuracies, axis=0)\n",
        "        all_fold_acc_history.append(all_rounds_mean_accuracy)\n",
        "\n",
        "        all_rounds_fps = np.mean(rounds_fps)\n",
        "        all_rounds_fns = np.mean(rounds_fns)\n",
        "        all_fold_false_positives.append(all_rounds_fps)\n",
        "        all_fold_false_negatives.append(all_rounds_fns)\n",
        "\n",
        "        print(f\"Fold no {fold+1} . ALL ACC = {all_rounds_mean_accuracy}: total:{len(y_test)} : fps:{all_fold_false_positives} : nps:{all_fold_false_negatives}\")\n",
        "        timestamp = str(int(time.time()))  # Obtain the current timestamp\n",
        "        with open('/content/drive/MyDrive/Ghost Lab/cog 2023/camera-ready/Zelda-data/active/model_fold'+str(fold+1)+'-'+timestamp+'.pickle', 'wb') as handle:\n",
        "            pickle.dump(classifier, handle)\n",
        "\n",
        "    end_time = time.time()\n",
        "    execution_time = end_time - start_time\n",
        "\n",
        "    return  classifier, all_fold_acc_history , execution_time, all_fold_false_positives, all_fold_false_negatives\n",
        "\n"
      ],
      "metadata": {
        "id": "Zg_HMEUurach"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Margin Sampling\n",
        "import pickle\n",
        "\n",
        "STRATEGY = margin_sampling\n",
        "N_INSTANCES = 1\n",
        "N_QUERIES = 100\n",
        "MAX_EPOCHS = 50\n",
        "FRACTION = 0.6\n",
        "np.random.seed(75)  # Set the seed value to 42\n",
        "\n",
        "# Define the size of the level\n",
        "width = 29\n",
        "height = 13\n",
        "levels = []\n",
        "levels.extend(playable_levels)\n",
        "levels.extend(unplayable_levels)\n",
        "levels = np.array(levels)\n",
        "print(levels.shape)\n",
        "\n",
        "labels = []\n",
        "labels.extend(playable_levels_labels)\n",
        "labels.extend(unplayable_levels_labels)\n",
        "labels = np.array(labels)\n",
        "print(labels.shape)\n",
        "\n",
        "classifier_1, all_fold_acc_history_1, execution_time_1, fps_1,fns_1= train_active_learner(STRATEGY, N_QUERIES, N_INSTANCES,MAX_EPOCHS, FRACTION)\n",
        "\n",
        "print(f\"Execution time: {execution_time_1} seconds\")\n",
        "\n",
        "print(fps_1)\n",
        "print(fns_1)\n",
        "\n",
        "# Calculate average accuracy and standard error for each epoch\n",
        "mean_accuracy_1 = np.mean(all_fold_acc_history_1, axis=0)\n",
        "std_error_1 = np.std(all_fold_acc_history_1, axis=0) / np.sqrt(len(all_fold_acc_history_1))\n",
        "std_dev_1 = np.std(all_fold_acc_history_1, axis=0)\n",
        "# Plotting\n",
        "epochs_1 = range(1, len(mean_accuracy_1) + 1)\n",
        "# Calculate upper and lower bounds for the fill region\n",
        "lower_bound_1 = mean_accuracy_1 - std_dev_1\n",
        "upper_bound_1 = mean_accuracy_1 + std_dev_1\n",
        "\n",
        "plt.errorbar(epochs_1, mean_accuracy_1, yerr=std_error_1, capsize=3)\n",
        "plt.xlabel('Queries')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Average Accuracy over Epoch with Standard Error')\n",
        "plt.show()\n",
        "\n",
        "plt.plot(epochs_1, mean_accuracy_1, label='Average Accuracy')\n",
        "plt.fill_between(epochs_1, lower_bound_1, upper_bound_1, alpha=0.3, label='Standard Deviation')\n",
        "plt.xlabel('Queries')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Average Accuracy over Queries with Standard Deviation')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "from datetime import datetime\n",
        "timestamp = str(int(time.time()))  # Obtain the current timestamp\n",
        "with open('/content/drive/MyDrive/Ghost Lab/cog 2023/camera-ready/Zelda-data/active/model_'+timestamp+'.pickle', 'wb') as handle:\n",
        "    pickle.dump(classifier_1, handle)\n",
        "\n",
        "json_object = json.dumps({\n",
        "    'STRATEGY' : 'margin_sampling', 'num_instances' : N_INSTANCES,\n",
        "    'num_queries' : N_QUERIES, 'epochs' : MAX_EPOCHS,\n",
        "    'fraction': FRACTION,\n",
        "    'weight_decay' : 0.001, 'learning_rate': '?',\n",
        "    'execution_time' : execution_time_1}, indent=4)\n",
        "with open('/content/drive/MyDrive/Ghost Lab/cog 2023/camera-ready/Zelda-data/active/parameters-'+timestamp+'.json', 'w') as outfile:\n",
        "    outfile.write(json_object)\n",
        "\n",
        "with open('/content/drive/MyDrive/Ghost Lab/cog 2023/camera-ready/Zelda-data/active/results-'+timestamp+'.pickle', 'wb') as handle:\n",
        "    pickle.dump({'all_fold_acc_history' : all_fold_acc_history_1,'fps' : fps_1, 'fns': fns_1}, handle)\n"
      ],
      "metadata": {
        "id": "PcbDIE_GgXyk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Random Sampling\n",
        "STRATEGY = random_query_strategy\n",
        "N_INSTANCES = 1\n",
        "N_QUERIES = 100\n",
        "MAX_EPOCHS = 20\n",
        "FRACTION = 0.55\n",
        "np.random.seed(30)  # Set the seed value to 42\n",
        "\n",
        "# Define the size of the level\n",
        "width = 29\n",
        "height = 13\n",
        "levels = []\n",
        "levels.extend(playable_levels)\n",
        "levels.extend(unplayable_levels)\n",
        "levels = np.array(levels)\n",
        "print(levels.shape)\n",
        "\n",
        "labels = []\n",
        "labels.extend(playable_levels_labels)\n",
        "labels.extend(unplayable_levels_labels)\n",
        "labels = np.array(labels)\n",
        "print(labels.shape)\n",
        "\n",
        "classifier_2, all_fold_acc_history_2, execution_time_2, fps_2,fns_2= train_active_learner(STRATEGY, N_QUERIES, N_INSTANCES,MAX_EPOCHS, FRACTION)\n",
        "\n",
        "print(f\"Execution time: {execution_time_1} seconds\")\n",
        "\n",
        "print(fps_2)\n",
        "print(fns_2)\n",
        "\n",
        "# Calculate average accuracy and standard error for each epoch\n",
        "mean_accuracy_2 = np.mean(all_fold_acc_history_2, axis=0)\n",
        "std_error_2 = np.std(all_fold_acc_history_2, axis=0) / np.sqrt(len(all_fold_acc_history_2))\n",
        "std_dev_2 = np.std(all_fold_acc_history_2, axis=0)\n",
        "# Plotting\n",
        "epochs_2 = range(1, len(mean_accuracy_2) + 1)\n",
        "# Calculate upper and lower bounds for the fill region\n",
        "lower_bound_2 = mean_accuracy_2 - std_dev_2\n",
        "upper_bound_2 = mean_accuracy_2 + std_dev_2\n",
        "\n",
        "plt.errorbar(epochs_2, mean_accuracy_2, yerr=std_error_2, capsize=3)\n",
        "plt.xlabel('Queries')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Average Accuracy over Epoch with Standard Error')\n",
        "plt.show()\n",
        "\n",
        "plt.plot(epochs_2, mean_accuracy_2, label='Average Accuracy')\n",
        "plt.fill_between(epochs_2, lower_bound_2, upper_bound_2, alpha=0.3, label='Standard Deviation')\n",
        "plt.xlabel('Queries')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Average Accuracy over Queries with Standard Deviation')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "from datetime import datetime\n",
        "timestamp = str(int(time.time()))  # Obtain the current timestamp\n",
        "with open('/content/drive/MyDrive/Ghost Lab/cog 2023/camera-ready/Zelda-data/active/model_'+timestamp+'.pickle', 'wb') as handle:\n",
        "    pickle.dump(classifier_2, handle)\n",
        "\n",
        "json_object = json.dumps({\n",
        "    'STRATEGY' : 'random_sampling', 'num_instances' : N_INSTANCES,\n",
        "    'num_queries' : N_QUERIES, 'epochs' : MAX_EPOCHS,\n",
        "    'fraction': FRACTION,\n",
        "    'weight_decay' : 0.001, 'learning_rate': '?',\n",
        "    'execution_time' : execution_time_2}, indent=4)\n",
        "with open('/content/drive/MyDrive/Ghost Lab/cog 2023/camera-ready/Zelda-data/active/parameters-'+timestamp+'.json', 'w') as outfile:\n",
        "    outfile.write(json_object)\n",
        "\n",
        "with open('/content/drive/MyDrive/Ghost Lab/cog 2023/camera-ready/Zelda-data/active/results-'+timestamp+'.pickle', 'wb') as handle:\n",
        "    pickle.dump({'all_fold_acc_history' : all_fold_acc_history_2,'fps' : fps_2, 'fns': fns_2}, handle)"
      ],
      "metadata": {
        "id": "vw6t_zmAg-oR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Plots"
      ],
      "metadata": {
        "id": "FZt1zvLnJsbr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy import stats\n",
        "\n",
        "\n",
        "\n",
        "# Calculate average accuracy and standard error for each epoch\n",
        "mean_accuracy_1 = np.mean(all_fold_acc_history_1, axis=0)\n",
        "std_error_1 = np.std(all_fold_acc_history_1, axis=0) / np.sqrt(len(all_fold_acc_history_1))\n",
        "std_dev_1 = np.std(all_fold_acc_history_1, axis=0)\n",
        "# Plotting\n",
        "epochs_1 = range(10, len(mean_accuracy_1) + 10)\n",
        "# Calculate upper and lower bounds for the fill region\n",
        "lower_bound_1 = mean_accuracy_1 - std_dev_1\n",
        "upper_bound_1 = mean_accuracy_1 + std_dev_1\n",
        "\n",
        "\n",
        "# Calculate average accuracy and standard error for each epoch\n",
        "mean_accuracy_2 = np.mean(all_fold_acc_history_2, axis=0)\n",
        "\n",
        "std_error_2 = np.std(all_fold_acc_history_2, axis=0) / np.sqrt(len(all_fold_acc_history_2))\n",
        "std_dev_2 = np.std(all_fold_acc_history_2, axis=0)\n",
        "# Plotting\n",
        "epochs_2 = range(10, len(mean_accuracy_2) + 10)\n",
        "print(epochs_2)\n",
        "# Calculate upper and lower bounds for the fill region\n",
        "lower_bound_2 = mean_accuracy_2 - std_dev_2\n",
        "upper_bound_2 = mean_accuracy_2 + std_dev_2\n",
        "\n",
        "plt.plot(epochs_1,  mean_accuracy_1, color='b', linestyle='-', label='Margin Sampling')\n",
        "plt.fill_between(epochs_1, lower_bound_1, upper_bound_1, alpha=0.3)\n",
        "plt.plot(epochs_2,  mean_accuracy_2,color='r', linestyle='-', label='Random Sampling')\n",
        "plt.fill_between(epochs_2, lower_bound_2, upper_bound_2, alpha=0.3)\n",
        "#plt.axhline(y=np.mean(all_fold_acc_history), color='g', linestyle='--', label='Passive Learner (2480 samples)')\n",
        "plt.ylim(0.45, 0.8)\n",
        "#plt.xlim(10, 410)\n",
        "#plt.xticks(np.arange(10,410, 50))\n",
        "plt.xlabel('#Samples')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Average Accuracy over Samples')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "rMvQGkEEET3K"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}